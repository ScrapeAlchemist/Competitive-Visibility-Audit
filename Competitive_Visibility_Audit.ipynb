{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1tUL_fZdIOy"
      },
      "source": [
        "# Web Execution Layer Workshop\n",
        "## Competitive Intelligence with Bright Data APIs\n",
        "\n",
        "This workshop demonstrates how to build a competitive intelligence pipeline using Bright Data's Web Execution Layer:\n",
        "\n",
        "1. **SERP Ranking** - Find your position vs competitors in search results\n",
        "2. **Deep Dive** - Scrape competitor pages as markdown and analyze with LLM\n",
        "3. **AI Perception** - See what ChatGPT, Perplexity, and other AI engines say about your brand\n",
        "4. **Deep Competitor Analysis** - Extract and analyze deeper pages (pricing, features)\n",
        "5. **Executive Summary** - GPT-powered analysis of all findings\n",
        "\n",
        "---\n",
        "\n",
        "### Prerequisites\n",
        "- Bright Data account with API access\n",
        "- SERP API zone configured\n",
        "- Web Unlocker zone configured\n",
        "- OpenAI API key (pre-configured in environment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuBIUu9ldIOz"
      },
      "source": [
        "## Section 0: Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ez3wV9XgdIOz"
      },
      "outputs": [],
      "source": [
        "# Install required dependencies\n",
        "# - requests: For making HTTP calls to Bright Data APIs\n",
        "# - openai: For GPT-powered keyword generation and analysis\n",
        "!pip install -q requests openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwHmJaDJdIOz",
        "outputId": "52e82839-a839-4bec-d903-961c95de9cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded:\n",
            "  Brand: Lusha\n",
            "  Domain: Lusha.com\n",
            "  Country: us\n",
            "  Bright Data API: âœ“ configured\n",
            "  OpenAI API: âœ“ configured\n"
          ]
        }
      ],
      "source": [
        "#@title ðŸ‘‰ Enter Your Company Details Here\n",
        "#@markdown ---\n",
        "#@markdown Enter your company information below, then run the rest of the notebook.\n",
        "#@markdown ---\n",
        "\n",
        "MY_BRAND = \"\" #@param {type:\"string\"}\n",
        "MY_DOMAIN = \"\" #@param {type:\"string\"}\n",
        "COUNTRY = \"us\" #@param {type:\"string\"}\n",
        "\n",
        "# ============================================\n",
        "# API credentials (from Colab secrets)\n",
        "# ============================================\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['BRIGHTDATA_API_TOKEN'] = userdata.get('BRIGHTDATA_API_TOKEN')\n",
        "os.environ['BRIGHTDATA_ZONE_SERP'] = userdata.get('BRIGHTDATA_ZONE_SERP')\n",
        "os.environ['BRIGHTDATA_ZONE_UNLOCKER'] = userdata.get('BRIGHTDATA_ZONE_UNLOCKER')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "BRIGHTDATA_API_TOKEN = os.environ.get(\"BRIGHTDATA_API_TOKEN\")\n",
        "BRIGHTDATA_ZONE_SERP = os.environ.get(\"BRIGHTDATA_ZONE_SERP\", \"serp_api1\")\n",
        "BRIGHTDATA_ZONE_UNLOCKER = os.environ.get(\"BRIGHTDATA_ZONE_UNLOCKER\", \"unlocker\")\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Import required libraries\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "print(f\"  Brand: {MY_BRAND}\")\n",
        "print(f\"  Domain: {MY_DOMAIN}\")\n",
        "print(f\"  Country: {COUNTRY}\")\n",
        "print(f\"  Bright Data API: {'âœ“ configured' if BRIGHTDATA_API_TOKEN else 'âœ— missing'}\")\n",
        "print(f\"  OpenAI API: {'âœ“ configured' if OPENAI_API_KEY else 'âœ— missing'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hq1xc2CdIO0",
        "outputId": "8ad54924-d9b3-428c-a3a8-502b63d45f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating research keywords with GPT...\n",
            "\n",
            "GPT generated keywords:\n",
            "  - B2B contact database\n",
            "  - sales prospecting tool\n",
            "  - lead generation software\n"
          ]
        }
      ],
      "source": [
        "# Execute: Use GPT to generate relevant keywords based on the brand/domain\n",
        "\n",
        "print(\"Generating research keywords with GPT...\\n\")\n",
        "\n",
        "# Retry initializing OpenAI client if it's None\n",
        "if openai_client is None and OPENAI_API_KEY:\n",
        "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "    print(\"Retried OpenAI client initialization...\")\n",
        "\n",
        "if openai_client:\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"You are a competitive intelligence expert. Given a brand and domain, generate 3 search keywords that potential customers would use to find this type of product/service.\n",
        "\n",
        "Return ONLY valid JSON in this exact format, no other text:\n",
        "{\"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]}\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Brand: {MY_BRAND}\\nDomain: {MY_DOMAIN}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        generated = json.loads(response.choices[0].message.content)\n",
        "        keywords_list = generated['keywords']\n",
        "        print(\"GPT generated keywords:\")\n",
        "        for kw in keywords_list:\n",
        "            print(f\"  - {kw}\")\n",
        "    except:\n",
        "        keywords_list = [f\"{MY_BRAND} alternatives\", f\"best {MY_DOMAIN.split('.')[0]} tools\"]\n",
        "        print(f\"Using fallback keywords: {keywords_list}\")\n",
        "else:\n",
        "    keywords_list = [MY_BRAND, f\"{MY_BRAND} review\", f\"{MY_BRAND} alternatives\"]\n",
        "    print(f\"No OpenAI API key - using fallback keywords: {keywords_list}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ66n4LQdIO0"
      },
      "source": [
        "---\n",
        "## Section 1: SERP Ranking\n",
        "\n",
        "In this section, we'll use Bright Data's SERP API to:\n",
        "1. Search Google for your target keywords\n",
        "2. Find where YOUR domain ranks in the results\n",
        "3. Identify your main competitors\n",
        "\n",
        "### How the SERP API Works\n",
        "The SERP API sends requests through Bright Data's proxy network and returns structured JSON data from Google search results. The `brd_json=1` parameter tells the API to parse the HTML and return clean JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RdwpDhXdIO0",
        "outputId": "8a6ab944-42ae-4067-e0ca-d83420064e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ search_keyword() function defined\n"
          ]
        }
      ],
      "source": [
        "# Setup: Define function to search Google via SERP API\n",
        "\n",
        "def search_keyword(keyword, country):\n",
        "    \"\"\"\n",
        "    Search Google for a keyword and return structured results.\n",
        "    \"\"\"\n",
        "    search_url = f\"https://www.google.com/search?q={requests.utils.quote(keyword)}&gl={country}&brd_json=1\"\n",
        "\n",
        "    print(f\"  Searching: {keyword}...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.brightdata.com/request\",\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            },\n",
        "            json={\n",
        "                \"zone\": BRIGHTDATA_ZONE_SERP,\n",
        "                \"url\": search_url,\n",
        "                \"format\": \"raw\"\n",
        "            },\n",
        "            timeout=60\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            print(f\"    âœ— Error: {response.status_code} - {response.text[:100]}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    âœ— Exception: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"âœ“ search_keyword() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pBEjYQpdIO0",
        "outputId": "906330d2-002e-4185-82e5-8ceb73c057bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching 3 keywords in us...\n",
            "\n",
            "  Searching: B2B contact database...\n",
            "  Searching: sales prospecting tool...\n",
            "  Searching: lead generation software...\n",
            "    âœ“ 'lead generation software': Found 9 organic results\n",
            "    âœ“ 'B2B contact database': Found 10 organic results\n",
            "    âœ“ 'sales prospecting tool': Found 10 organic results\n",
            "\n",
            "âœ“ Completed 3/3 searches\n"
          ]
        }
      ],
      "source": [
        "# Execute: Run SERP searches for all keywords in parallel\n",
        "\n",
        "print(f\"Searching {len(keywords_list)} keywords in {COUNTRY}...\\n\")\n",
        "\n",
        "serp_results = {}\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    futures = {}\n",
        "    for keyword in keywords_list:\n",
        "        future = executor.submit(search_keyword, keyword, COUNTRY)\n",
        "        futures[future] = keyword\n",
        "        time.sleep(0.05)  # 50ms delay between API calls\n",
        "\n",
        "    for future in as_completed(futures):\n",
        "        keyword = futures[future]\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            serp_results[keyword] = result\n",
        "            organic_count = len(result.get('organic', []))\n",
        "            print(f\"    âœ“ '{keyword}': Found {organic_count} organic results\")\n",
        "        else:\n",
        "            print(f\"    âœ— '{keyword}': No results\")\n",
        "\n",
        "print(f\"\\nâœ“ Completed {len(serp_results)}/{len(keywords_list)} searches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NVZHGuXdIO1",
        "outputId": "ce3c55bf-cc0d-44a2-ba4a-4b02ce65921b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ extract_domain() function defined\n"
          ]
        }
      ],
      "source": [
        "# Setup: Define helper function to extract domain from URL\n",
        "\n",
        "def extract_domain(url):\n",
        "    \"\"\"Extract the root domain from a URL.\"\"\"\n",
        "    try:\n",
        "        from urllib.parse import urlparse\n",
        "        parsed = urlparse(url)\n",
        "        domain = parsed.netloc.lower()\n",
        "        if domain.startswith('www.'):\n",
        "            domain = domain[4:]\n",
        "        return domain\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "print(\"âœ“ extract_domain() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFSJ1nopdIO1",
        "outputId": "55d9406e-b2b7-474b-a2d3-f32817c83a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing rankings for Lusha.com...\n",
            "\n",
            "'lead generation software': Not in top 10\n",
            "'B2B contact database': Not in top 10\n",
            "'sales prospecting tool': Not in top 10\n",
            "\n",
            "âœ“ Analyzed 3 keywords\n",
            "âœ“ Found 21 unique competitor domains\n"
          ]
        }
      ],
      "source": [
        "# Execute: Analyze SERP results to find YOUR ranking\n",
        "# This cell processes the raw SERP data to extract:\n",
        "# - Your brand's position for each keyword\n",
        "# - List of competitors and their positions\n",
        "# - Frequency count of competitors across all keywords\n",
        "\n",
        "# Initialize rankings dictionary to store all analysis results\n",
        "rankings = {\n",
        "    'brand': MY_BRAND,\n",
        "    'domain': MY_DOMAIN,\n",
        "    'country': COUNTRY,\n",
        "    'keywords': {},           # Per-keyword ranking data\n",
        "    'all_competitors': {},    # Competitor frequency across all keywords\n",
        "    'main_competitors': []    # Top competitors (set in next cell)\n",
        "}\n",
        "\n",
        "print(f\"Analyzing rankings for {MY_DOMAIN}...\\n\")\n",
        "\n",
        "# Loop through each keyword's SERP results\n",
        "for keyword, data in serp_results.items():\n",
        "    # Get organic (non-ad) search results\n",
        "    organic = data.get('organic', [])\n",
        "\n",
        "    my_position = None\n",
        "    competitors = []\n",
        "\n",
        "    # Check top 10 results for each keyword\n",
        "    for result in organic[:10]:\n",
        "        # Use the rank field directly from Bright Data's API response\n",
        "        rank = result.get('rank')\n",
        "        url = result.get('link', '')\n",
        "        domain = extract_domain(url)\n",
        "        title = result.get('title', '')\n",
        "\n",
        "        # Check if this result is OUR domain\n",
        "        if domain and MY_DOMAIN.lower() in domain:\n",
        "            my_position = rank\n",
        "        else:\n",
        "            # It's a competitor - add to list\n",
        "            competitors.append({\n",
        "                'position': rank,\n",
        "                'domain': domain,\n",
        "                'title': title\n",
        "            })\n",
        "            # Track how often each competitor appears across keywords\n",
        "            if domain:\n",
        "                rankings['all_competitors'][domain] = rankings['all_competitors'].get(domain, 0) + 1\n",
        "\n",
        "    # Store results for this keyword\n",
        "    rankings['keywords'][keyword] = {\n",
        "        'my_position': my_position,\n",
        "        'competitors': competitors[:5]  # Keep top 5 competitors per keyword\n",
        "    }\n",
        "\n",
        "    # Print summary for this keyword\n",
        "    position_str = f\"#{my_position}\" if my_position else \"Not in top 10\"\n",
        "    print(f\"'{keyword}': {position_str}\")\n",
        "\n",
        "print(f\"\\nâœ“ Analyzed {len(rankings['keywords'])} keywords\")\n",
        "print(f\"âœ“ Found {len(rankings['all_competitors'])} unique competitor domains\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBZuYCNddIO1",
        "outputId": "33fea188-d5fe-438a-afab-bdf63642dd48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "MAIN COMPETITORS (by frequency across keywords):\n",
            "  dealfront.com: appears in 2 keyword(s)\n",
            "  kaspr.io: appears in 2 keyword(s)\n",
            "  cognism.com: appears in 2 keyword(s)\n",
            "  seamless.ai: appears in 2 keyword(s)\n",
            "  apollo.io: appears in 1 keyword(s)\n"
          ]
        }
      ],
      "source": [
        "# Execute: Identify main competitors by counting how many times each domain\n",
        "# appears across all keyword searches. Use GPT to filter out non-competitors\n",
        "# (forums, review sites, social media, etc.)\n",
        "\n",
        "# Get top 10 domains by frequency (we'll filter with GPT)\n",
        "candidate_competitors = sorted(\n",
        "    [(domain, count) for domain, count in rankings['all_competitors'].items()],\n",
        "    key=lambda x: x[1],\n",
        "    reverse=True\n",
        ")[:10]\n",
        "\n",
        "# Use GPT to filter out non-competitors\n",
        "if openai_client and candidate_competitors:\n",
        "    domains_list = [d[0] for d in candidate_competitors]\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"\"\"You are analyzing search results for {MY_BRAND} ({MY_DOMAIN}).\n",
        "\n",
        "Given a list of domains, identify which are ACTUAL BUSINESS COMPETITORS (companies offering similar products/services).\n",
        "\n",
        "EXCLUDE: forums (reddit, quora), social media (linkedin, twitter, youtube), review sites (g2, capterra, trustpilot), news sites, Wikipedia, GitHub, Amazon, etc.\n",
        "\n",
        "Return ONLY a JSON array of competitor domains, no other text:\n",
        "[\"competitor1.com\", \"competitor2.com\"]\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Domains found in search results: {json.dumps(domains_list)}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=200\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        filtered_domains = json.loads(response.choices[0].message.content)\n",
        "        # Rebuild list with counts, preserving order\n",
        "        main_competitors = [(d, c) for d, c in candidate_competitors if d in filtered_domains][:5]\n",
        "    except:\n",
        "        # Fallback to original list if GPT parsing fails\n",
        "        main_competitors = candidate_competitors[:5]\n",
        "else:\n",
        "    main_competitors = candidate_competitors[:5]\n",
        "\n",
        "rankings['main_competitors'] = [{'domain': d, 'frequency': c} for d, c in main_competitors]\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"MAIN COMPETITORS (by frequency across keywords):\")\n",
        "for comp in main_competitors:\n",
        "    print(f\"  {comp[0]}: appears in {comp[1]} keyword(s)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2KGqrjKdIO1",
        "outputId": "b2773671-c412-47c6-f81b-135516500379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "SERP RANKING SUMMARY: Lusha\n",
            "============================================================\n",
            "Keyword                        Position        Top Competitor\n",
            "------------------------------------------------------------\n",
            "B2B contact database           Not ranked      apollo.io\n",
            "sales prospecting tool         Not ranked      dealfront.com\n",
            "lead generation software       Not ranked      zendesk.com\n",
            "\n",
            "------------------------------------------------------------\n",
            "Top competitors to watch:\n",
            "  1. dealfront.com\n",
            "  2. kaspr.io\n",
            "  3. cognism.com\n"
          ]
        }
      ],
      "source": [
        "# Display rankings summary table\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"SERP RANKING SUMMARY: {MY_BRAND}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Keyword':<30} {'Position':<15} {'Top Competitor'}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "for keyword, data in rankings['keywords'].items():\n",
        "    pos = data['my_position']\n",
        "    position_str = f\"#{pos}\" if pos else \"Not ranked\"\n",
        "    top_comp = data['competitors'][0]['domain'] if data['competitors'] else \"N/A\"\n",
        "    print(f\"{keyword:<30} {position_str:<15} {top_comp}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Top competitors to watch:\")\n",
        "for i, comp in enumerate(rankings['main_competitors'][:3], 1):\n",
        "    print(f\"  {i}. {comp['domain']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd0752_CdIO1",
        "outputId": "10c06972-f5e1-4b22-981a-407c90d73020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating GPT analysis of SERP results...\n",
            "\n",
            "GPT ANALYSIS:\n",
            "----------------------------------------\n",
            "- Lusha is currently not ranking in the top 10 for critical keywords tied to its core offering, indicating weak SEO presence compared to competitors like apollo.io and dealfront.com.\n",
            "- Competitors such as dealfront.com and kaspr.io dominate key terms, suggesting they have stronger content strategies or backlink profiles targeting B2B contact databases and prospecting tools.\n",
            "- To improve rankings, Lusha should optimize for these high-value keywords with targeted content, enhanced on-page SEO, and actively build authoritative backlinks.\n",
            "- Consider auditing and benchmarking against top competitorsâ€™ SEO strategies to identify content gaps and technical improvements for Lusha.com.\n"
          ]
        }
      ],
      "source": [
        "# Execute: GPT summarizes SERP findings\n",
        "\n",
        "if openai_client:\n",
        "    print(\"Generating GPT analysis of SERP results...\\n\")\n",
        "\n",
        "    serp_summary = f\"\"\"\n",
        "    Brand: {MY_BRAND}\n",
        "    Domain: {MY_DOMAIN}\n",
        "    Market: {COUNTRY}\n",
        "\n",
        "    Keyword Rankings:\n",
        "    \"\"\"\n",
        "    for kw, data in rankings['keywords'].items():\n",
        "        pos = data['my_position'] or \"Not in top 10\"\n",
        "        serp_summary += f\"\\n    - '{kw}': Position {pos}\"\n",
        "        if data['competitors']:\n",
        "            serp_summary += f\" (Top competitor: {data['competitors'][0]['domain']})\"\n",
        "\n",
        "    serp_summary += f\"\\n\\n    Main Competitors: {', '.join([c['domain'] for c in rankings['main_competitors'][:3]])}\"\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a competitive intelligence analyst. Provide brief, actionable insights based on SERP ranking data. Be concise - 3-4 bullet points max.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Analyze these SERP rankings and provide key insights:\\n{serp_summary}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    serp_analysis = response.choices[0].message.content\n",
        "    print(\"GPT ANALYSIS:\")\n",
        "    print(\"-\"*40)\n",
        "    print(serp_analysis)\n",
        "else:\n",
        "    serp_analysis = None\n",
        "    print(\"Skipping GPT analysis (no OpenAI API key configured)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHqIuCKxdIO1"
      },
      "source": [
        "---\n",
        "## Section 2: Deep Dive into Competitor Pages\n",
        "\n",
        "Now that we've identified the top competitors in our search results, let's scrape those pages and analyze their strategies.\n",
        "\n",
        "We'll use Bright Data's **Web Unlocker** to fetch **your domain and competitor pages** as clean markdown, then use GPT to extract competitive insights like:\n",
        "- Their main value proposition\n",
        "- Key features they highlight\n",
        "- Trust signals (testimonials, client logos, stats)\n",
        "- Pricing transparency\n",
        "- Relevant URLs for deeper analysis (pricing pages, feature pages, etc.)\n",
        "\n",
        "This allows us to compare your messaging directly against your competitors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usMdZoDxdIO1",
        "outputId": "72666d99-4410-439b-811f-31367794a8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ scrape_as_markdown() function defined\n"
          ]
        }
      ],
      "source": [
        "# Setup: Define function to scrape pages as markdown using Web Unlocker\n",
        "\n",
        "def scrape_as_markdown(url):\n",
        "    \"\"\"\n",
        "    Scrape a URL and return the content as clean markdown using Web Unlocker.\n",
        "    \"\"\"\n",
        "    print(f\"  Scraping: {url[:50]}...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.brightdata.com/request\",\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            },\n",
        "            json={\n",
        "                \"zone\": BRIGHTDATA_ZONE_UNLOCKER,\n",
        "                \"url\": url,\n",
        "                \"format\": \"raw\",\n",
        "                \"data_format\": \"markdown\"\n",
        "            },\n",
        "            timeout=60\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            markdown_content = response.text\n",
        "            print(f\"    âœ“ Got {len(markdown_content)} chars of markdown\")\n",
        "            return {'markdown': markdown_content[:10000], 'url': url}\n",
        "        else:\n",
        "            print(f\"    âœ— Error: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    âœ— Error: {str(e)[:50]}\")\n",
        "        return None\n",
        "\n",
        "print(\"âœ“ scrape_as_markdown() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR401_mOdIO2",
        "outputId": "c2c4be0e-395d-468c-df7f-c0c7cdd05522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting pages to analyze...\n",
            "\n",
            "  âœ“ Added our domain: https://Lusha.com\n",
            "  âœ“ Added competitor: https://dealfront.com\n",
            "  âœ“ Added competitor: https://kaspr.io\n",
            "  âœ“ Added competitor: https://cognism.com\n",
            "\n",
            "Selected 4 pages to deep-dive:\n",
            "  1. https://Lusha.com (YOUR DOMAIN)\n",
            "  2. https://dealfront.com \n",
            "  3. https://kaspr.io \n",
            "  4. https://cognism.com \n"
          ]
        }
      ],
      "source": [
        "# Execute: Select top competitor HOMEPAGES and our own domain to analyze\n",
        "\n",
        "print(\"Selecting pages to analyze...\\n\")\n",
        "\n",
        "competitor_urls = []\n",
        "\n",
        "# Add our own domain first for comparison\n",
        "my_url = f\"https://{MY_DOMAIN}\"\n",
        "competitor_urls.append(my_url)\n",
        "print(f\"  âœ“ Added our domain: {my_url}\")\n",
        "\n",
        "# Add top competitor homepages (not blog posts from SERP)\n",
        "for comp in rankings['main_competitors'][:3]:\n",
        "    domain = comp['domain']\n",
        "    url = f\"https://{domain}\"\n",
        "    if url not in competitor_urls:\n",
        "        competitor_urls.append(url)\n",
        "        print(f\"  âœ“ Added competitor: {url}\")\n",
        "\n",
        "print(f\"\\nSelected {len(competitor_urls)} pages to deep-dive:\")\n",
        "for i, url in enumerate(competitor_urls, 1):\n",
        "    label = \"(YOUR DOMAIN)\" if MY_DOMAIN.lower() in url.lower() else \"\"\n",
        "    print(f\"  {i}. {url} {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn-kub5vdIO2",
        "outputId": "902a450b-69d9-4095-c7b1-56bffab6c2e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping 4 pages...\n",
            "\n",
            "  Scraping: https://Lusha.com...\n",
            "  Scraping: https://dealfront.com...\n",
            "  Scraping: https://kaspr.io...\n",
            "  Scraping: https://cognism.com...\n",
            "    âœ“ Got 19533 chars of markdown\n",
            "    âœ“ https://dealfront.com... \n",
            "    âœ“ Got 9589 chars of markdown\n",
            "    âœ“ https://kaspr.io... \n",
            "    âœ“ Got 23826 chars of markdown\n",
            "    âœ“ https://cognism.com... \n",
            "    âœ“ Got 20645 chars of markdown\n",
            "    âœ“ https://Lusha.com... (YOUR DOMAIN)\n",
            "\n",
            "âœ“ Successfully scraped 4/4 pages\n"
          ]
        }
      ],
      "source": [
        "# Execute: Scrape the pages as markdown in parallel\n",
        "\n",
        "print(f\"Scraping {len(competitor_urls)} pages...\\n\")\n",
        "\n",
        "competitor_content = []\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    futures = {}\n",
        "    for url in competitor_urls:\n",
        "        future = executor.submit(scrape_as_markdown, url)\n",
        "        futures[future] = url\n",
        "        time.sleep(0.05)  # 50ms delay between API calls\n",
        "\n",
        "    for future in as_completed(futures):\n",
        "        url = futures[future]\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            label = \"(YOUR DOMAIN)\" if MY_DOMAIN in url else \"\"\n",
        "            print(f\"    âœ“ {url[:50]}... {label}\")\n",
        "            competitor_content.append(result)\n",
        "\n",
        "print(f\"\\nâœ“ Successfully scraped {len(competitor_content)}/{len(competitor_urls)} pages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiZddM5udIO2",
        "outputId": "3b9004a6-1348-4d64-976f-cd4d46b17cd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing 4 pages with GPT in parallel...\n",
            "\n",
            "\n",
            "==================================================\n",
            "[COMPETITOR] https://cognism.com...\n",
            "==================================================\n",
            "{\n",
            "  \"value_proposition\": \"Cognism provides up-to-date, high-quality B2B sales intelligence data and actionable insights to help businesses drive intelligent prospecting, boost connect rates, and build pipeline across EMEA markets.\",\n",
            "  \"features\": [\n",
            "    \"Comprehensive data coverage with millions of verified company and decision-maker contacts, including mobile numbers that boost connect rates by up to 3x.\",\n",
            "    \"Purpose-built platform for sales, marketing, and revenue operations teams to target accounts with precise insights and buyer signals.\",\n",
            "    \"Seamless integrations and Data-as-a-Service to deliver enriched data directly into your tech stack or warehouse.\"\n",
            "  ],\n",
            "  \"target_audience\": \"B2B sales, marketing, and revenue operations professionals and teams, especially those selling into EMEA markets looking for reliable, GDPR-compliant sales intelligence to enhance demand generation and pipeline growth.\",\n",
            "  \"pricing_info\": \"Pricing details are not directly visible on the homepage but are accessible via a dedicated pricing page (https://www.cognism.com/pricing).\",\n",
            "  \"trust_signals\": \"Trusted by over 4000 businesses globally including notable clients like Monday.com, Aircall, Xero, Hootsuite, Amex, and KPMG; recognized with multiple G2 badges for Market Leadership, Momentum, and Best Results in Sales Intelligence.\",\n",
            "  \"relevant_urls\": [\n",
            "    \"https://www.cognism.com/pricing\",\n",
            "    \"https://www.cognism.com/features\",\n",
            "    \"https://www.cognism.com/sales-companion\",\n",
            "    \"https://www.cognism.com/signal-data\",\n",
            "    \"https://www.cognism.com/data-as-a-service\",\n",
            "    \"https://www.cognism.com/integrations\",\n",
            "    \"https://www.cognism.com/case-studies\",\n",
            "    \"https://www.cognism.com/customer-reviews\",\n",
            "    \"https://www.cognism.com/about-us\",\n",
            "    \"https://www.cognism.com/compliance\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "==================================================\n",
            "[COMPETITOR] https://dealfront.com...\n",
            "==================================================\n",
            "{\n",
            "  \"value_proposition\": \"Dealfront helps sales and marketing teams efficiently build a high-quality pipeline by identifying and prioritizing ICP-fit accounts showing real buying intent, driving predictable revenue growth.\",\n",
            "  \"features\": [\n",
            "    \"Identify and segment ideal customer profile (ICP) fit accounts already visiting your website with firmographic and intent filters.\",\n",
            "    \"Highlight and prioritize leads showing strong buying intent to focus sales efforts on prospects most likely to convert.\",\n",
            "    \"Integrate seamlessly with popular CRMs (Salesforce, HubSpot, Pipedrive) and marketing platforms (Google Ads) to maximize campaign and sales effectiveness.\"\n",
            "  ],\n",
            "  \"target_audience\": \"B2B sales and marketing teams focused on pipeline growth, lead prioritization, and efficient resource allocation in Europe, particularly those needing GDPR-compliant, high-quality B2B data.\",\n",
            "  \"pricing_info\": \"7-day free trial available with no credit card required. Detailed pricing information is accessible via the /pricing/ page (https://www.dealfront.com/pricing/).\",\n",
            "  \"trust_signals\": \"Over 830 G2 reviews; multiple client success stories including Recrutis Consulting (570% boost in connect rates), Instaffo, COSMO CONSULT (30% lead conversion improvement, 70% cost reduction), and ARC (25-40 high-quality leads daily).\",\n",
            "  \"relevant_urls\": [\n",
            "    \"https://www.dealfront.com/pricing/\",\n",
            "    \"https://www.dealfront.com/platform/features/icp-insights/\",\n",
            "    \"https://www.dealfront.com/web-visitors/\",\n",
            "    \"https://www.dealfront.com/integrations/\",\n",
            "    \"https://www.dealfront.com/customers/\",\n",
            "    \"https://www.dealfront.com/request-demo/\",\n",
            "    \"https://www.dealfront.com/resources/playbooks/\",\n",
            "    \"https://help.dealfront.com/en/\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "==================================================\n",
            "[COMPETITOR] https://kaspr.io...\n",
            "==================================================\n",
            "{\n",
            "  \"value_proposition\": \"Kaspr provides instant access to accurate, GDPR-compliant European B2B contact data with an easy-to-use LinkedIn Chrome extension and all-in-one prospecting dashboard to help sales, recruitment, and founders grow their pipeline and close deals.\",\n",
            "  \"features\": [\n",
            "    \"Access to over 500 million verified and compliant phone numbers and email addresses from 150+ sources\",\n",
            "    \"A LinkedIn Chrome Extension to get contact data directly from prospects' profiles in one click\",\n",
            "    \"Integration with favorite sales and CRM tools and an all-in-one dashboard to manage leads and automate workflows\"\n",
            "  ],\n",
            "  \"target_audience\": \"Sales teams aiming to hit quotas, recruiters looking to place top candidates, and founders seeking to accelerate business growth by accessing accurate B2B contact data and managing prospecting efficiently.\",\n",
            "  \"pricing_info\": \"Kaspr offers a free plan to get started without requiring a credit card; detailed pricing can be found on the pricing page linked from the homepage.\",\n",
            "  \"trust_signals\": \"Rated 4.4/5 stars on G2 with over 750 reviews; customer testimonials highlight increased appointments and superior data quality; recognized as a Leader and High Performer in G2 badges; GDPR and CCPA compliant.\",\n",
            "  \"relevant_urls\": [\n",
            "    \"https://www.kaspr.io/pricing\",\n",
            "    \"https://www.kaspr.io/linkedin-chrome-extension\",\n",
            "    \"https://www.kaspr.io/data-enrichment\",\n",
            "    \"https://www.kaspr.io/why-kaspr/integrations\",\n",
            "    \"https://www.kaspr.io/sales\",\n",
            "    \"https://www.kaspr.io/recruitment\",\n",
            "    \"https://www.kaspr.io/founders\",\n",
            "    \"https://www.kaspr.io/why-kaspr/customer-stories\",\n",
            "    \"https://www.kaspr.io/blog\",\n",
            "    \"https://help.kaspr.io/\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "==================================================\n",
            "[YOUR DOMAIN] https://Lusha.com...\n",
            "==================================================\n",
            "{\n",
            "  \"value_proposition\": \"Lusha provides accurate B2B data enriched with real-time buying signals and AI-powered workflows to keep revenue teams in sync and accelerate deal wins.\",\n",
            "  \"features\": [\n",
            "    \"Extensive database of 300M+ verified contacts with complete company context for precise prospecting.\",\n",
            "    \"Automated lead enrichment that keeps CRM records complete and sales-ready with validated contact details and firmographic data.\",\n",
            "    \"Real-time buying signals including job changes, hiring momentum, funding news, and technology adoption to engage prospects at the right time.\",\n",
            "    \"Automated GTM workflows like list building, enrichment, scoring, routing, and CRM updates to streamline sales processes and reduce manual work.\",\n",
            "    \"API and integrations to ensure all GTM tools share one clean and updated source of truth.\"\n",
            "  ],\n",
            "  \"target_audience\": \"Revenue teams including sales, marketing, revops, and recruiting professionals aiming to optimize prospecting, lead enrichment, and engagement to grow pipeline and accelerate deals.\",\n",
            "  \"pricing_info\": \"Pricing is available via a dedicated pricing page at https://www.lusha.com/pricing/ but no detailed pricing info is shown on the homepage.\",\n",
            "  \"trust_signals\": [\n",
            "    \"Customer success stats: 3X more outbound leads, 25% more deals, 1000% more ROI, 100% pipeline growth.\",\n",
            "    \"Customer logos and case studies from companies like CARTO, Devere Group, Oracle NetSuite, and Fireant.\",\n",
            "    \"Compliance certifications including GDPR (ePrivacyseal GmbH), CCPA (TrustArc), and ISO 31700 for privacy by design.\",\n",
            "    \"Global data coverage and accuracy statements ensuring reliable business-only data.\"\n",
            "  ],\n",
            "  \"relevant_urls\": [\n",
            "    \"https://www.lusha.com/pricing/\",\n",
            "    \"https://www.lusha.com/b2b-prospecting-tool/\",\n",
            "    \"https://www.lusha.com/lusha-extension/\",\n",
            "    \"https://www.lusha.com/warm-outbound-intent-data/\",\n",
            "    \"https://www.lusha.com/alerts/\",\n",
            "    \"https://www.lusha.com/ai-recommendations/\",\n",
            "    \"https://www.lusha.com/ai-playlists/\",\n",
            "    \"https://www.lusha.com/engage/\",\n",
            "    \"https://www.lusha.com/conversations/\",\n",
            "    \"https://www.lusha.com/automations/\",\n",
            "    \"https://www.lusha.com/mcp-server-ai-data-integration/\",\n",
            "    \"https://www.lusha.com/lusha-api/\",\n",
            "    \"https://www.lusha.com/lusha-integrations/\",\n",
            "    \"https://www.lusha.com/crm-data-enrichment/\",\n",
            "    \"https://www.lusha.com/customers/\",\n",
            "    \"https://www.lusha.com/trust-center/\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "âœ“ Analyzed 4 pages\n"
          ]
        }
      ],
      "source": [
        "# Execute: GPT analyzes pages and extracts relevant URLs\n",
        "# This cell sends each scraped page to GPT for analysis.\n",
        "# GPT extracts structured insights and identifies deeper pages to scrape later.\n",
        "\n",
        "def analyze_page_with_gpt(page):\n",
        "    \"\"\"Analyze a single page with GPT and return insights.\"\"\"\n",
        "    is_my_domain = MY_DOMAIN in page['url']\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"Analyze this page and extract:\n",
        "1. Main value proposition (1 sentence)\n",
        "2. Key features/benefits highlighted (2-3 bullets)\n",
        "3. Target audience signals\n",
        "4. Pricing info if visible\n",
        "5. Trust signals (testimonials, client logos, stats)\n",
        "6. Relevant URLs for deeper analysis, ordered by importance (pricing page first, then features, etc.)\n",
        "\n",
        "Return JSON format:\n",
        "{\n",
        "  \"value_proposition\": \"...\",\n",
        "  \"features\": [\"...\", \"...\"],\n",
        "  \"target_audience\": \"...\",\n",
        "  \"pricing_info\": \"...\",\n",
        "  \"trust_signals\": \"...\",\n",
        "  \"relevant_urls\": [\"https://...\", \"https://...\"]\n",
        "}\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"URL: {page['url']}\\n\\nPage Content:\\n{page['markdown'][:10000]}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        analysis = json.loads(response.choices[0].message.content)\n",
        "    except:\n",
        "        analysis = {'raw': response.choices[0].message.content, 'relevant_urls': []}\n",
        "\n",
        "    return {\n",
        "        'url': page['url'],\n",
        "        'is_my_domain': is_my_domain,\n",
        "        'analysis': analysis\n",
        "    }\n",
        "\n",
        "if openai_client and competitor_content:\n",
        "    print(f\"Analyzing {len(competitor_content)} pages with GPT in parallel...\\n\")\n",
        "\n",
        "    competitor_insights = []\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = {executor.submit(analyze_page_with_gpt, page): page for page in competitor_content}\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            page = futures[future]\n",
        "            result = future.result()\n",
        "            competitor_insights.append(result)\n",
        "\n",
        "            # Display results\n",
        "            label = \"YOUR DOMAIN\" if result['is_my_domain'] else \"COMPETITOR\"\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"[{label}] {result['url'][:50]}...\")\n",
        "            print(f\"{'='*50}\")\n",
        "            print(json.dumps(result['analysis'], indent=2))\n",
        "\n",
        "    print(f\"\\nâœ“ Analyzed {len(competitor_insights)} pages\")\n",
        "else:\n",
        "    competitor_insights = []\n",
        "    print(\"No pages to analyze\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok79NdG2uPg2",
        "outputId": "8aa87507-f759-4038-842f-fe564b637726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL: https://Lusha.com\n",
            "Analysis: {'value_proposition': 'Lusha provides accurate B2B data enriched with real-time buying signals and AI-powered workflows to keep revenue teams in sync and accelerate deal wins.', 'features': ['Extensive database of 300M+ verified contacts with complete company context for precise prospecting.', 'Automated lead enrichment that keeps CRM records complete and sales-ready with validated contact details and firmographic data.', 'Real-time buying signals including job changes, hiring momentum, funding news, and technology adoption to engage prospects at the right time.', 'Automated GTM workflows like list building, enrichment, scoring, routing, and CRM updates to streamline sales processes and reduce manual work.', 'API and integrations to ensure all GTM tools share one clean and updated source of truth.'], 'target_audience': 'Revenue teams including sales, marketing, revops, and recruiting professionals aiming to optimize prospecting, lead enrichment, and engagement to grow pipeline and accelerate deals.', 'pricing_info': 'Pricing is available via a dedicated pricing page at https://www.lusha.com/pricing/ but no detailed pricing info is shown on the homepage.', 'trust_signals': ['Customer success stats: 3X more outbound leads, 25% more deals, 1000% more ROI, 100% pipeline growth.', 'Customer logos and case studies from companies like CARTO, Devere Group, Oracle NetSuite, and Fireant.', 'Compliance certifications including GDPR (ePrivacyseal GmbH), CCPA (TrustArc), and ISO 31700 for privacy by design.', 'Global data coverage and accuracy statements ensuring reliable business-only data.'], 'relevant_urls': ['https://www.lusha.com/pricing/', 'https://www.lusha.com/b2b-prospecting-tool/', 'https://www.lusha.com/lusha-extension/', 'https://www.lusha.com/warm-outbound-intent-data/', 'https://www.lusha.com/alerts/', 'https://www.lusha.com/ai-recommendations/', 'https://www.lusha.com/ai-playlists/', 'https://www.lusha.com/engage/', 'https://www.lusha.com/conversations/', 'https://www.lusha.com/automations/', 'https://www.lusha.com/mcp-server-ai-data-integration/', 'https://www.lusha.com/lusha-api/', 'https://www.lusha.com/lusha-integrations/', 'https://www.lusha.com/crm-data-enrichment/', 'https://www.lusha.com/customers/', 'https://www.lusha.com/trust-center/']}\n"
          ]
        }
      ],
      "source": [
        "for insight in competitor_insights:\n",
        "    if insight.get('is_my_domain'):\n",
        "        print(f\"URL: {insight['url']}\")\n",
        "        print(f\"Analysis: {insight['analysis']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLnGrfRHdIO2"
      },
      "source": [
        "---\n",
        "## Section 3: AI Perception\n",
        "\n",
        "In this section, we'll query AI engines (ChatGPT, Perplexity, Grok, Gemini) to see:\n",
        "1. What they say when users ask about your industry\n",
        "2. Whether YOUR brand is mentioned in their responses\n",
        "3. How you compare to competitors in AI recommendations\n",
        "\n",
        "### How AI Engine Scraping Works\n",
        "Bright Data's Web Scraper API has pre-built endpoints for each AI engine. We send a prompt, and the API handles:\n",
        "- Opening the AI engine in a real browser\n",
        "- Submitting the prompt\n",
        "- Waiting for and extracting the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMpyNo7UdIO2",
        "outputId": "e739d538-2cc6-4901-8e3d-b3b669e12a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI Engines configured:\n",
            "  - ChatGPT\n",
            "  - Perplexity\n",
            "  - Grok\n",
            "  - Gemini\n"
          ]
        }
      ],
      "source": [
        "# AI Engine configuration\n",
        "\n",
        "AI_ENGINES = {\n",
        "    'chatgpt': {\n",
        "        'dataset_id': 'gd_m7aof0k82r803d5bjm',\n",
        "        'name': 'ChatGPT',\n",
        "        'url': 'https://chatgpt.com/'\n",
        "    },\n",
        "    'perplexity': {\n",
        "        'dataset_id': 'gd_m7dhdot1vw9a7gc1n',\n",
        "        'name': 'Perplexity',\n",
        "        'url': 'https://www.perplexity.ai'\n",
        "    },\n",
        "    'grok': {\n",
        "        'dataset_id': 'gd_m8ve0u141icu75ae74',\n",
        "        'name': 'Grok',\n",
        "        'url': 'https://grok.com/'\n",
        "    },\n",
        "    'gemini': {\n",
        "        'dataset_id': 'gd_mbz66arm2mf9cu856y',\n",
        "        'name': 'Gemini',\n",
        "        'url': 'https://gemini.google.com/'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"AI Engines configured:\")\n",
        "for key, config in AI_ENGINES.items():\n",
        "    print(f\"  - {config['name']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GIYOPwLdIO2",
        "outputId": "8ed91234-7918-47f3-9b18-3dcecd0cccad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating AI perception queries with GPT...\n",
            "\n",
            "Generated queries (brand NOT mentioned):\n",
            "  - What are the top B2B contact databases for accurate lead information?\n",
            "  - Which sales prospecting tools provide verified business emails and phone numbers?\n",
            "  - Best lead generation software for improving B2B sales outreach?\n"
          ]
        }
      ],
      "source": [
        "# Execute: GPT generates GENERIC industry queries for AI engines\n",
        "# These queries should NOT mention our brand - we want to see if AI engines\n",
        "# naturally recommend us when users ask about the industry/problem space\n",
        "\n",
        "print(\"Generating AI perception queries with GPT...\\n\")\n",
        "\n",
        "if openai_client:\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"Generate 3 questions that potential customers would ask AI assistants when looking for this type of product/service.\n",
        "\n",
        "IMPORTANT: Do NOT mention the brand name in any query. These should be generic industry questions like:\n",
        "- \"What's the best B2B contact database?\"\n",
        "- \"Which sales prospecting tools are most accurate?\"\n",
        "- \"Best tools for finding business email addresses\"\n",
        "\n",
        "We want to see if AI engines naturally recommend the brand without being asked about it directly.\n",
        "\n",
        "Return ONLY valid JSON array, no other text:\n",
        "[\"query 1\", \"query 2\", \"query 3\"]\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Brand: {MY_BRAND}\\nDomain: {MY_DOMAIN}\\nIndustry keywords: {', '.join(keywords_list)}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        ai_queries = json.loads(response.choices[0].message.content)\n",
        "        print(\"Generated queries (brand NOT mentioned):\")\n",
        "        for q in ai_queries:\n",
        "            print(f\"  - {q}\")\n",
        "    except:\n",
        "        ai_queries = [f\"best {keywords_list[0]} tools\", \"best sales prospecting software\", \"most accurate B2B contact database\"]\n",
        "        print(f\"Using fallback queries: {ai_queries}\")\n",
        "else:\n",
        "    ai_queries = [f\"best {keywords_list[0]} tools\", \"best sales prospecting software\", \"most accurate B2B contact database\"]\n",
        "    print(f\"Using default queries: {ai_queries}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7aliR3hdIO2",
        "outputId": "6452e4a5-f709-4890-faa1-a1e4cfe13b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ trigger_ai_query() function defined\n"
          ]
        }
      ],
      "source": [
        "# Setup: Define function to trigger AI engine query\n",
        "# This function sends a prompt to an AI engine and returns a snapshot_id.\n",
        "# The snapshot_id is used to poll for results in the next step.\n",
        "\n",
        "def trigger_ai_query(engine_key, prompt, country):\n",
        "    \"\"\"Step 1: Send prompt to AI engine, get snapshot_id back.\"\"\"\n",
        "    engine = AI_ENGINES[engine_key]\n",
        "\n",
        "    # Handle Gemini not supporting Israel\n",
        "    query_country = country.upper() if not (engine_key == 'gemini' and country.upper() == 'IL') else ''\n",
        "\n",
        "    try:\n",
        "        # Gemini uses different payload format (input wrapper)\n",
        "        if engine_key == 'gemini':\n",
        "            payload = {\n",
        "                \"input\": [{\n",
        "                    \"url\": engine['url'],\n",
        "                    \"prompt\": prompt,\n",
        "                    \"country\": query_country\n",
        "                }]\n",
        "            }\n",
        "        else:\n",
        "            # ChatGPT, Perplexity, Grok use array directly\n",
        "            payload = [{\n",
        "                \"url\": engine['url'],\n",
        "                \"prompt\": prompt,\n",
        "                \"country\": query_country\n",
        "            }]\n",
        "\n",
        "        response = requests.post(\n",
        "            f\"https://api.brightdata.com/datasets/v3/trigger?dataset_id={engine['dataset_id']}\",\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            },\n",
        "            json=payload,\n",
        "            timeout=30\n",
        "        )\n",
        "\n",
        "        # API returns 200 with snapshot_id on success\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            snapshot_id = data.get('snapshot_id')\n",
        "            if snapshot_id:\n",
        "                return snapshot_id\n",
        "            else:\n",
        "                print(f\"    âœ— {engine['name']}: No snapshot_id - {str(data)[:100]}\")\n",
        "                return None\n",
        "        else:\n",
        "            print(f\"    âœ— {engine['name']}: HTTP {response.status_code} - {response.text[:100]}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    âœ— {engine['name']}: {str(e)[:100]}\")\n",
        "        return None\n",
        "\n",
        "print(\"âœ“ trigger_ai_query() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MLVMqWxxoUib",
        "outputId": "1d6209f7-5b32-4400-e5c7-34ce52ad774b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Querying 4 engines Ã— 3 queries...\n",
            "(Using 3x redundancy for speed)\n",
            "\n",
            "Triggering AI engine requests...\n",
            "\n",
            "âœ“ Triggered 36 snapshot requests\n",
            "  (12 unique tasks Ã— 3 redundant requests each)\n"
          ]
        }
      ],
      "source": [
        "# Execute: Phase 1 - Trigger all AI engine requests in parallel\n",
        "\n",
        "engines_to_query = ['chatgpt', 'perplexity', 'grok', 'gemini']\n",
        "\n",
        "print(f\"Querying {len(engines_to_query)} engines Ã— {len(ai_queries)} queries...\")\n",
        "print(f\"(Using {REDUNDANT_REQUESTS}x redundancy for speed)\\n\")\n",
        "\n",
        "# Build list of all engine + query combinations\n",
        "all_tasks = [(engine, query) for query in ai_queries for engine in engines_to_query]\n",
        "\n",
        "print(\"Triggering AI engine requests...\")\n",
        "\n",
        "pending_snapshots = []  # List of (engine, query, snapshot_id)\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=20) as executor:\n",
        "    futures = {}\n",
        "    for engine, query in all_tasks:\n",
        "        # Send REDUNDANT_REQUESTS identical requests per task\n",
        "        for _ in range(REDUNDANT_REQUESTS):\n",
        "            future = executor.submit(trigger_ai_query, engine, query, COUNTRY)\n",
        "            futures[future] = (engine, query)\n",
        "            time.sleep(0.05)\n",
        "\n",
        "    for future in as_completed(futures):\n",
        "        engine, query = futures[future]\n",
        "        snapshot_id = future.result()\n",
        "        if snapshot_id:\n",
        "            pending_snapshots.append((engine, query, snapshot_id))\n",
        "\n",
        "print(f\"\\nâœ“ Triggered {len(pending_snapshots)} snapshot requests\")\n",
        "print(f\"  ({len(all_tasks)} unique tasks Ã— {REDUNDANT_REQUESTS} redundant requests each)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LKGGlk4iobOT",
        "outputId": "ed5a5773-6ddf-43b5-a5b2-b8c23c238587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for snapshots to complete...\n",
            "(This may take 1-3 minutes)\n",
            "\n",
            "  ... 0/12 complete (2s elapsed)\n",
            "  ... 0/12 complete (9s elapsed)\n",
            "  âœ“ Perplexity: Which sales prospecting tools provi...\n",
            "  ... 1/12 complete (16s elapsed)\n",
            "  âœ“ Perplexity: Best lead generation software for i...\n",
            "  ... 2/12 complete (23s elapsed)\n",
            "  ... 2/12 complete (30s elapsed)\n",
            "  ... 2/12 complete (38s elapsed)\n",
            "  âœ“ Gemini: Best lead generation software for i...\n",
            "  âœ“ Grok: Which sales prospecting tools provi...\n",
            "  âœ“ Gemini: Which sales prospecting tools provi...\n",
            "  ... 5/12 complete (45s elapsed)\n",
            "  âœ“ Gemini: What are the top B2B contact databa...\n",
            "  âœ“ ChatGPT: What are the top B2B contact databa...\n",
            "  âœ“ Grok: Best lead generation software for i...\n",
            "  âœ“ Perplexity: What are the top B2B contact databa...\n",
            "  ... 9/12 complete (51s elapsed)\n",
            "  ... 9/12 complete (57s elapsed)\n",
            "  ... 9/12 complete (62s elapsed)\n",
            "  âœ“ ChatGPT: Which sales prospecting tools provi...\n",
            "  ... 10/12 complete (68s elapsed)\n",
            "  ... 10/12 complete (73s elapsed)\n",
            "  âœ“ ChatGPT: Best lead generation software for i...\n",
            "  ... 11/12 complete (78s elapsed)\n",
            "  âœ“ Grok: What are the top B2B contact databa...\n",
            "  ... 12/12 complete (83s elapsed)\n",
            "\n",
            "âœ“ All 12 tasks completed!\n",
            "\n",
            "âœ“ 12 snapshots ready for download\n"
          ]
        }
      ],
      "source": [
        "# Execute: Phase 2 - Poll snapshots until ready\n",
        "\n",
        "print(\"Waiting for snapshots to complete...\")\n",
        "print(\"(This may take 1-3 minutes)\\n\")\n",
        "\n",
        "ready_snapshots = []  # List of (engine, query, snapshot_id)\n",
        "max_wait = 180  # 3 minutes max\n",
        "start_time = time.time()\n",
        "\n",
        "# Track which (engine, query) pairs we've already got results for\n",
        "completed_tasks = set()\n",
        "\n",
        "while (time.time() - start_time) < max_wait:\n",
        "    # Check if we have all unique tasks completed\n",
        "    if len(completed_tasks) >= len(all_tasks):\n",
        "        print(f\"\\nâœ“ All {len(all_tasks)} tasks completed!\")\n",
        "        break\n",
        "\n",
        "    for engine, query, snapshot_id in pending_snapshots:\n",
        "        # Skip if we already have a result for this engine+query\n",
        "        if (engine, query) in completed_tasks:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            response = requests.get(\n",
        "                f\"https://api.brightdata.com/datasets/v3/progress/{snapshot_id}\",\n",
        "                headers={\"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\"},\n",
        "                timeout=10\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                status = response.json().get('status')\n",
        "                if status == 'ready':\n",
        "                    ready_snapshots.append((engine, query, snapshot_id))\n",
        "                    completed_tasks.add((engine, query))\n",
        "                    print(f\"  âœ“ {AI_ENGINES[engine]['name']}: {query[:35]}...\")\n",
        "                elif status == 'failed':\n",
        "                    # Mark as completed so we don't keep checking\n",
        "                    completed_tasks.add((engine, query))\n",
        "                    print(f\"  âœ— {AI_ENGINES[engine]['name']}: {query[:35]}... (failed)\")\n",
        "        except:\n",
        "            pass  # Will retry on next loop\n",
        "\n",
        "    # Progress update\n",
        "    elapsed = int(time.time() - start_time)\n",
        "    print(f\"  ... {len(completed_tasks)}/{len(all_tasks)} complete ({elapsed}s elapsed)\")\n",
        "    time.sleep(5)\n",
        "\n",
        "print(f\"\\nâœ“ {len(ready_snapshots)} snapshots ready for download\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQWgA-YonCX",
        "outputId": "67acfe7d-b58e-4946-93a6-1b55853e4c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading results...\n",
            "\n",
            "  âœ“ Grok: Which sales prospecting tools provi...\n",
            "  âœ“ Perplexity: Which sales prospecting tools provi...\n",
            "  âœ“ Gemini: Which sales prospecting tools provi...\n",
            "  âœ“ Gemini: What are the top B2B contact databa...\n",
            "  âœ“ Gemini: Best lead generation software for i...\n",
            "  âœ“ Perplexity: Best lead generation software for i...\n",
            "  âœ“ Grok: Best lead generation software for i...\n",
            "  âœ“ ChatGPT: Best lead generation software for i...\n",
            "  âœ“ Grok: What are the top B2B contact databa...\n",
            "  âœ“ ChatGPT: Which sales prospecting tools provi...\n",
            "  âœ“ Perplexity: What are the top B2B contact databa...\n",
            "  âœ“ ChatGPT: What are the top B2B contact databa...\n",
            "\n",
            "âœ“ Got 12/12 responses\n"
          ]
        }
      ],
      "source": [
        "# Execute: Phase 3 - Download results from ready snapshots (in parallel)\n",
        "\n",
        "print(\"Downloading results...\\n\")\n",
        "\n",
        "ai_results = []\n",
        "downloaded_tasks = set()\n",
        "\n",
        "def download_result(engine, query, snapshot_id):\n",
        "    \"\"\"Download a single snapshot result.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(\n",
        "            f\"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json\",\n",
        "            headers={\"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\"},\n",
        "            timeout=30\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if isinstance(data, list) and len(data) > 0:\n",
        "                item = data[0]\n",
        "                # Extract the response in markdown\n",
        "                content = item.get('answer_text_markdown', '')\n",
        "                return {\n",
        "                    'engine': engine,\n",
        "                    'engine_name': AI_ENGINES[engine]['name'],\n",
        "                    'query': query,\n",
        "                    'content': content\n",
        "                }\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    futures = {}\n",
        "    for engine, query, snapshot_id in ready_snapshots:\n",
        "        # Skip duplicates (from redundancy)\n",
        "        if (engine, query) in downloaded_tasks:\n",
        "            continue\n",
        "        downloaded_tasks.add((engine, query))\n",
        "\n",
        "        future = executor.submit(download_result, engine, query, snapshot_id)\n",
        "        futures[future] = (engine, query)\n",
        "\n",
        "    for future in as_completed(futures):\n",
        "        engine, query = futures[future]\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            ai_results.append(result)\n",
        "            print(f\"  âœ“ {AI_ENGINES[engine]['name']}: {query[:35]}...\")\n",
        "\n",
        "print(f\"\\nâœ“ Got {len(ai_results)}/{len(all_tasks)} responses\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVEDC4MPdIO2",
        "outputId": "8510dca7-99bb-412c-9c8b-58623bde5460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ check_brand_mention() function defined\n"
          ]
        }
      ],
      "source": [
        "# Setup: Define function to check brand mentions using LLM\n",
        "\n",
        "def check_brand_mention(text, brand):\n",
        "    \"\"\"Use LLM to check if brand is mentioned and extract position if listed.\"\"\"\n",
        "    if not text or not openai_client:\n",
        "        return {'mentioned': False, 'position': None}\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"\"\"Check if \\\"{brand}\\\" is mentioned in the text. Account for spelling variations.\n",
        "\n",
        "Return ONLY valid JSON:\n",
        "{{\"mentioned\": true/false, \"position\": null or number if in a ranked list}}\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": text[:5000]\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=100\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        return json.loads(response.choices[0].message.content)\n",
        "    except:\n",
        "        return {'mentioned': False, 'position': None}\n",
        "\n",
        "print(\"âœ“ check_brand_mention() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwX6Xb8xdIO2",
        "outputId": "872a3613-3548-4dad-b952-f67a89347f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking 12 responses for 'Lusha' mentions...\n",
            "\n",
            "[Grok] What are the top B2B contact databa...\n",
            "  âœ“ MENTIONED (#5)\n",
            "\n",
            "[Gemini] Which sales prospecting tools provi...\n",
            "  âœ“ MENTIONED (#3)\n",
            "\n",
            "[Perplexity] Which sales prospecting tools provi...\n",
            "  âœ— Not mentioned\n",
            "\n",
            "[ChatGPT] Which sales prospecting tools provi...\n",
            "  âœ“ MENTIONED (#2)\n",
            "\n",
            "[Perplexity] Best lead generation software for i...\n",
            "  âœ— Not mentioned\n",
            "\n",
            "[Gemini] What are the top B2B contact databa...\n",
            "  âœ“ MENTIONED (#4)\n",
            "\n",
            "[Grok] Which sales prospecting tools provi...\n",
            "  âœ“ MENTIONED (#4)\n",
            "\n",
            "[ChatGPT] Best lead generation software for i...\n",
            "  âœ“ MENTIONED (#9)\n",
            "\n",
            "[ChatGPT] What are the top B2B contact databa...\n",
            "  âœ“ MENTIONED (#3)\n",
            "\n",
            "[Grok] Best lead generation software for i...\n",
            "  âœ“ MENTIONED (#3)\n",
            "\n",
            "[Perplexity] What are the top B2B contact databa...\n",
            "  âœ“ MENTIONED (#3)\n",
            "\n",
            "[Gemini] Best lead generation software for i...\n",
            "  âœ— Not mentioned\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Execute: Check each AI response for brand mentions\n",
        "\n",
        "print(f\"Checking {len(ai_results)} responses for '{MY_BRAND}' mentions...\\n\")\n",
        "\n",
        "for result in ai_results:\n",
        "    mention = check_brand_mention(result['content'], MY_BRAND)\n",
        "    result['mentioned'] = mention['mentioned']\n",
        "    result['position'] = mention['position']\n",
        "\n",
        "    status = \"âœ“ MENTIONED\" if mention['mentioned'] else \"âœ— Not mentioned\"\n",
        "    pos = f\" (#{mention['position']})\" if mention['position'] else \"\"\n",
        "    print(f\"[{result['engine_name']}] {result['query'][:35]}...\")\n",
        "    print(f\"  {status}{pos}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdnC5GXEdIO2",
        "outputId": "e4dba204-ee48-4f4e-cd12-1ac2e4c7420f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating GPT analysis of AI perception...\n",
            "\n",
            "GPT ANALYSIS:\n",
            "----------------------------------------\n",
            "- Lusha has consistent visibility across multiple AI engines (Grok, Gemini, ChatGPT, Perplexity) for queries related to B2B contact databases and sales prospecting tools, often ranking within the top 5 results.\n",
            "- ChatGPT and Gemini position Lusha highly (positions #2 to #4), indicating strong recommendation strength on these platforms.\n",
            "- Perplexity shows mixed visibility, mentioning Lusha for B2B contact databases but not for lead generation or sales prospecting in certain queries, signaling some inconsistency.\n",
            "- Overall, Lusha is recognized and recommended by most AI engines but could improve presence in specific lead generation software queries, particularly on platforms like Perplexity and Gemini.\n"
          ]
        }
      ],
      "source": [
        "# Execute: GPT summarizes AI perception findings\n",
        "\n",
        "if openai_client and ai_results:\n",
        "    print(\"Generating GPT analysis of AI perception...\\n\")\n",
        "\n",
        "    # Build summary of all AI engine responses for GPT to analyze\n",
        "    ai_summary = f\"Brand: {MY_BRAND}\\n\\nAI Engine Responses:\\n\"\n",
        "    for r in ai_results:\n",
        "        mention_str = \"Mentioned\" if r['mentioned'] else \"Not mentioned\"\n",
        "        ai_summary += f\"\\n- [{r['engine_name']}] Query: '{r['query'][:40]}...'\\n\"\n",
        "        ai_summary += f\"  Result: {mention_str}\\n\"\n",
        "        if r.get('position'):\n",
        "            ai_summary += f\"  Position: #{r['position']}\\n\"\n",
        "\n",
        "    # Ask GPT-5 to analyze brand visibility across AI engines\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a brand visibility analyst. Analyze how AI engines perceive and recommend brands. Be concise - 3-4 bullet points max.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Analyze this brand's visibility across AI engines:\\n{ai_summary}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    # Store and display the analysis\n",
        "    ai_analysis = response.choices[0].message.content\n",
        "    print(\"GPT ANALYSIS:\")\n",
        "    print(\"-\"*40)\n",
        "    print(ai_analysis)\n",
        "else:\n",
        "    ai_analysis = None\n",
        "    print(\"Skipping GPT analysis (no OpenAI API key or no results)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtqJ3wShdIO3"
      },
      "source": [
        "---\n",
        "## Section 4: Deep Competitor Analysis\n",
        "\n",
        "In this section, we'll go deeper into competitor websites by:\n",
        "1. Using the URLs extracted in Section 2 (pricing pages, feature pages, etc.)\n",
        "2. Scraping those deeper pages\n",
        "3. Analyzing pricing, features, and messaging with GPT\n",
        "\n",
        "### Approach\n",
        "We'll use Bright Data's Web Unlocker API to scrape the relevant pages identified earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygJ_sufAdIO3",
        "outputId": "9b61f477-31ac-42d9-f8d7-f2de1c707ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ“ cognism.com \n",
            "  âœ“ dealfront.com \n",
            "  âœ“ kaspr.io \n",
            "  âœ“ lusha.com (YOUR DOMAIN)\n",
            "\n",
            "Scraping deeper pages in parallel...\n",
            "  Collected: 20 pages\n",
            "âœ“ Done\n"
          ]
        }
      ],
      "source": [
        "# Execute: Scrape deeper pages (pricing, features, etc.) from URLs extracted in Section 2\n",
        "# Get up to 5 deeper URLs per domain (your domain + top 3 competitors)\n",
        "# Only scrape URLs that match the source domain\n",
        "\n",
        "deep_urls = []\n",
        "\n",
        "# Collect relevant URLs per domain (up to 5 each, must match source domain)\n",
        "for insight in competitor_insights:\n",
        "    urls = insight.get('analysis', {}).get('relevant_urls', [])\n",
        "    source_domain = extract_domain(insight['url'])\n",
        "    label = \"(YOUR DOMAIN)\" if insight.get('is_my_domain') else \"\"\n",
        "\n",
        "    # Add up to 5 URLs that match the source domain\n",
        "    count = 0\n",
        "    for url in urls:\n",
        "        url_domain = extract_domain(url)\n",
        "        # Only include URLs from the same domain\n",
        "        if url_domain and source_domain and source_domain in url_domain:\n",
        "            if url not in deep_urls and count < 5:\n",
        "                deep_urls.append(url)\n",
        "                count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        print(f\"  âœ“ {source_domain} {label}\")\n",
        "\n",
        "print(f\"\\nScraping deeper pages in parallel...\")\n",
        "\n",
        "deep_content = []\n",
        "\n",
        "# Scrape all URLs in parallel\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    futures = {}\n",
        "    for url in deep_urls:\n",
        "        future = executor.submit(scrape_as_markdown, url, silent=True)\n",
        "        futures[future] = url\n",
        "        time.sleep(0.05)  # 50ms delay between API calls\n",
        "\n",
        "    for future in as_completed(futures):\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            deep_content.append(result)\n",
        "            print(f\"\\r  Collected: {len(deep_content)} pages\", end=\"\", flush=True)\n",
        "\n",
        "print(f\"\\nâœ“ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9Jf49YVdIO3",
        "outputId": "0b26629d-a98c-4f7e-c132-cd40e6cafca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grouped pages into 4 companies:\n",
            "  - dealfront.com: 6 pages \n",
            "  - kaspr.io: 6 pages \n",
            "  - cognism.com: 6 pages \n",
            "  - lusha.com: 6 pages (YOUR COMPANY)\n"
          ]
        }
      ],
      "source": [
        "# Setup: Group all scraped pages by company domain\n",
        "# Combines homepage content with deeper pages (pricing, features, etc.)\n",
        "\n",
        "company_content = {}\n",
        "\n",
        "# Add homepage content from competitor_content\n",
        "for page in competitor_content:\n",
        "    domain = extract_domain(page['url'])\n",
        "    if domain not in company_content:\n",
        "        company_content[domain] = {\n",
        "            'is_my_domain': MY_DOMAIN.lower() in domain,\n",
        "            'pages': []\n",
        "        }\n",
        "    company_content[domain]['pages'].append(page)\n",
        "\n",
        "# Add deep page content\n",
        "for page in deep_content:\n",
        "    domain = extract_domain(page['url'])\n",
        "    if domain in company_content:\n",
        "        company_content[domain]['pages'].append(page)\n",
        "\n",
        "print(f\"Grouped pages into {len(company_content)} companies:\")\n",
        "for domain, data in company_content.items():\n",
        "    label = \"(YOUR COMPANY)\" if data['is_my_domain'] else \"\"\n",
        "    print(f\"  - {domain}: {len(data['pages'])} pages {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NULK9oPxopo",
        "outputId": "25a652e4-0441-47df-e2d8-9c8ef40ff72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating company profiles...\n",
            "\n",
            "âœ“ [COMPETITOR] kaspr.io\n",
            "âœ“ [COMPETITOR] dealfront.com\n",
            "âœ“ [YOUR COMPANY] lusha.com\n",
            "âœ“ [COMPETITOR] cognism.com\n",
            "\n",
            "âœ“ Generated 4 company profiles\n"
          ]
        }
      ],
      "source": [
        "# Execute: Generate consolidated profile for each company\n",
        "\n",
        "def analyze_company(domain, data):\n",
        "    \"\"\"Analyze all pages from a company and return a consolidated profile.\"\"\"\n",
        "    combined_content = \"\"\n",
        "    for page in data['pages']:\n",
        "        combined_content += f\"\\n\\n--- {page['url']} ---\\n{page['markdown'][:5000]}\"\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"Analyze all pages from this company and create a consolidated profile.\n",
        "\n",
        "Return JSON format:\n",
        "{\n",
        "  \"company\": \"...\",\n",
        "  \"value_proposition\": \"1-2 sentences\",\n",
        "  \"features\": [\"feature 1\", \"feature 2\", \"feature 3\"],\n",
        "  \"pricing\": \"pricing details or 'Not available'\",\n",
        "  \"target_audience\": \"...\",\n",
        "  \"differentiators\": [\"diff 1\", \"diff 2\"]\n",
        "}\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Domain: {domain}\\n\\nPages:\\n{combined_content[:15000]}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        profile = json.loads(response.choices[0].message.content)\n",
        "    except:\n",
        "        profile = {'raw': response.choices[0].message.content}\n",
        "\n",
        "    profile['domain'] = domain\n",
        "    profile['is_my_domain'] = data['is_my_domain']\n",
        "    return profile\n",
        "\n",
        "# Analyze all companies in parallel\n",
        "print(\"Generating company profiles...\\n\")\n",
        "company_profiles = []\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    futures = {executor.submit(analyze_company, domain, data): domain for domain, data in company_content.items()}\n",
        "\n",
        "    for future in as_completed(futures):\n",
        "        domain = futures[future]\n",
        "        profile = future.result()\n",
        "        company_profiles.append(profile)\n",
        "\n",
        "        label = \"YOUR COMPANY\" if profile['is_my_domain'] else \"COMPETITOR\"\n",
        "        print(f\"âœ“ [{label}] {domain}\")\n",
        "\n",
        "print(f\"\\nâœ“ Generated {len(company_profiles)} company profiles\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBfFEQ9Gxopp",
        "outputId": "66a91e0b-e47f-4db4-cb33-b7f1a9fa82cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "[COMPETITOR] kaspr.io\n",
            "==================================================\n",
            "{\n",
            "  \"company\": \"Kaspr\",\n",
            "  \"value_proposition\": \"Kaspr provides sales, recruitment, and founding professionals with instant access to accurate, compliant, and verified European B2B contact data via an easy-to-use LinkedIn Chrome Extension and integrated platform, enabling faster lead generation, seamless workflow integration, and pipeline growth.\",\n",
            "  \"features\": [\n",
            "    \"Accurate contact data access for over 200 million profiles including 500M+ verified phone numbers and emails\",\n",
            "    \"LinkedIn Chrome Extension to extract contact information directly from prospect profiles\",\n",
            "    \"Bulk data enrichment for lead lists with real-time verified data from 150+ sources\",\n",
            "    \"Native integrations with leading CRMs (HubSpot, Salesforce, Pipedrive, Zoho CRM) and sales tools (Lemlist, Ringover, Aircall, Brevo, Zapier)\",\n",
            "    \"All-in-one prospect management dashboard with automation capabilities\",\n",
            "    \"GDPR and CCPA compliant data sourcing and handling\",\n",
            "    \"No onboarding required with quick start and available training/support resources\"\n",
            "  ],\n",
            "  \"pricing\": \"Available on the Kaspr website pricing page; details not directly provided in the analyzed content\",\n",
            "  \"target_audience\": \"Sales representatives, recruitment professionals, founders, and business teams focused on B2B lead generation and outreach primarily in Europe\",\n",
            "  \"differentiators\": [\n",
            "    \"Focus on European market with unmatched data quality and compliance\",\n",
            "    \"Seamless LinkedIn-integrated workflow allowing contact data retrieval without leaving filtered LinkedIn searches\",\n",
            "    \"Extensive integrations with popular CRM and sales outreach tools for streamlined prospecting and sales processes\"\n",
            "  ],\n",
            "  \"domain\": \"kaspr.io\",\n",
            "  \"is_my_domain\": false\n",
            "}\n",
            "\n",
            "==================================================\n",
            "[COMPETITOR] dealfront.com\n",
            "==================================================\n",
            "{\n",
            "  \"company\": \"Dealfront\",\n",
            "  \"value_proposition\": \"Dealfront offers a comprehensive B2B revenue engine platform that enables sales and marketing teams to create high-quality pipelines and accelerate revenue growth through accurate data, AI insights, and deep account intelligence.\",\n",
            "  \"features\": [\n",
            "    \"Dealfront AI for creating qualified pipelines faster\",\n",
            "    \"ICP Insights for spotting and segmenting best-fit website visitors instantly\",\n",
            "    \"Browser Extension to access compliant deep data on the go\",\n",
            "    \"Buyer Intent Signals to focus on prospects showing real buying intent\",\n",
            "    \"Leadfeeder for identifying companies visiting your website\",\n",
            "    \"Datacare to check, cleanse, enrich, and optimize company data\",\n",
            "    \"Promote module for targeted B2B display advertising\",\n",
            "    \"Target module providing compliant B2B data\",\n",
            "    \"Connect module for deep insights into target accounts\"\n",
            "  ],\n",
            "  \"pricing\": \"Not available. The website provides no explicit pricing details; users are encouraged to book a call to choose the right solution.\",\n",
            "  \"target_audience\": \"Sales and marketing teams in B2B companies, especially those looking to boost lead quality, conversion rates, and pipeline acceleration with compliant, high-quality European B2B data and AI-driven insights.\",\n",
            "  \"differentiators\": [\n",
            "    \"Focus on compliant and highly accurate B2B data for Europe\",\n",
            "    \"Integrated AI tools to generate qualified leads and automate intent scoring\",\n",
            "    \"Multiple modules catering to different stages of revenue generation (data cleansing, visitor identification, targeted ads, data enrichment)\",\n",
            "    \"Strong integrations with CRM and advertising platforms such as Salesforce, HubSpot, Pipedrive, and Google Ads\",\n",
            "    \"Comprehensive playbooks and support to power AI tools and automate workflows\"\n",
            "  ],\n",
            "  \"domain\": \"dealfront.com\",\n",
            "  \"is_my_domain\": false\n",
            "}\n",
            "\n",
            "==================================================\n",
            "[YOUR COMPANY] lusha.com\n",
            "==================================================\n",
            "{\n",
            "  \"company\": \"Lusha\",\n",
            "  \"value_proposition\": \"Lusha offers an AI-powered sales intelligence platform providing accurate B2B data enriched with real-time buying signals and AI workflows to accelerate pipeline growth and streamline revenue teams' efforts.\",\n",
            "  \"features\": [\n",
            "    \"B2B Contact & Company Search to find ideal prospects quickly\",\n",
            "    \"Chrome Extension for capturing leads on LinkedIn and other web sources\",\n",
            "    \"Buyer Intent data and real-time Signals & Alerts for in-market buyer identification\",\n",
            "    \"AI-driven Lead Streaming with daily matched leads and auto-updating prospect playlists\",\n",
            "    \"Automation tools for personalized email engagement and sales meeting analysis\",\n",
            "    \"Data integration with APIs, CRM enrichment, and multi-channel platform sync\",\n",
            "    \"Solutions tailored for sales teams, revenue operations, marketers, and recruiters\"\n",
            "  ],\n",
            "  \"pricing\": \"Flexible pricing plans suitable for companies of all sizes; detailed pricing available on their pricing page with a free start option and custom enterprise plans. Contact sales for detailed quotes.\",\n",
            "  \"target_audience\": \"Revenue teams including sales professionals, revenue operations, marketers, recruiters, and businesses ranging from SMBs to enterprises looking to scale sales and optimize demand generation.\",\n",
            "  \"differentiators\": [\n",
            "    \"Real-time buyer intent signals integrated with AI-powered workflows\",\n",
            "    \"Comprehensive automation and enrichment capabilities to keep CRM data fresh and actionable\",\n",
            "    \"Multi-channel prospecting tools including a Chrome extension and API integrations\",\n",
            "    \"Scalable solutions serving SMBs to enterprise-level organizations\",\n",
            "    \"Highly rated for ease of use and effectiveness in accelerating pipeline growth\"\n",
            "  ],\n",
            "  \"domain\": \"lusha.com\",\n",
            "  \"is_my_domain\": true\n",
            "}\n",
            "\n",
            "==================================================\n",
            "[COMPETITOR] cognism.com\n",
            "==================================================\n",
            "{\n",
            "  \"company\": \"Cognism\",\n",
            "  \"value_proposition\": \"Cognism is a premium sales intelligence platform that empowers GTM teams to break performance records, acquire highly targeted leads on-demand, and grow revenue by delivering high-quality, compliant data and actionable buyer insights.\",\n",
            "  \"features\": [\n",
            "    \"Sales Companion: a revenue growth center for GTM teams that integrates data and insights into workflows\",\n",
            "    \"Buyer signals: actionable insights to find and engage the next best customer\",\n",
            "    \"Data-as-a-Service: direct delivery of insights and data into customer data warehouses\",\n",
            "    \"Integrations: seamless syncing of high-quality data to existing tech stacks\",\n",
            "    \"Diamond Data\\u00ae: Cognism's proprietary data technology ensuring data quality and compliance\",\n",
            "    \"Compliance: GDPR and other data privacy regulation compliant data practices\",\n",
            "    \"Use case support for Sales, Marketing, and Revenue Operations teams\"\n",
            "  ],\n",
            "  \"pricing\": \"Pricing details are available upon request or consultation; publicly available specific pricing information is not provided on the website.\",\n",
            "  \"target_audience\": \"Sales, Marketing, and Revenue Operations professionals at B2B organizations seeking to accelerate pipeline generation, improve targeting, and grow revenue through premium sales intelligence and data-driven insights.\",\n",
            "  \"differentiators\": [\n",
            "    \"Proprietary Diamond Data\\u00ae technology guarantees high-quality, GDPR-compliant data\",\n",
            "    \"Comprehensive platform combining sales intelligence, buyer signals, data delivery, and integrations in one solution\",\n",
            "    \"Strong focus on compliance with global data privacy regulations\",\n",
            "    \"Used by over 4,000 companies worldwide, demonstrating established market trust\",\n",
            "    \"Tailored solutions for multiple go-to-market roles including Sales, Marketing, and RevOps\"\n",
            "  ],\n",
            "  \"domain\": \"cognism.com\",\n",
            "  \"is_my_domain\": false\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Display: Show each company profile\n",
        "\n",
        "for profile in company_profiles:\n",
        "    label = \"YOUR COMPANY\" if profile.get('is_my_domain') else \"COMPETITOR\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"[{label}] {profile.get('domain', 'Unknown')}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(json.dumps(profile, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSUyebTExopp",
        "outputId": "6dfdc02a-366e-4832-8630-da91b1ee1e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COMPETITIVE COMPARISON\n",
            "============================================================\n",
            "\n",
            "### 1. Comparison Table\n",
            "\n",
            "| Company    | Key Features                                                                                                     | Pricing                                     | Target Market                                   | Unique Differentiators                                      |\n",
            "|------------|-----------------------------------------------------------------------------------------------------------------|---------------------------------------------|------------------------------------------------|-------------------------------------------------------------|\n",
            "| **Lusha**  | - B2B Contact & Company Search<br>- Chrome Extension<br>- Buyer Intent Data & Signals<br>- AI Lead Streaming<br>- Automation for email & meeting analysis<br>- API & CRM integrations<br>- Multi-channel prospecting | Flexible plans, free option, custom enterprise pricing; details on website                          | Revenue teams (Sales, RevOps, Marketing, Recruiting) from SMB to Enterprise                          | - Real-time AI-driven intent signals<br>- Strong automation & enrichment<br>- Scalable enterprise & SMB use<br>- Multi-channel workflows |\n",
            "| **Kaspr**  | - 200M+ profiles, 500M+ verified contacts<br>- LinkedIn Chrome extension<br>- Bulk list enrichment<br>- Integrations (HubSpot, Salesforce, etc.)<br>- Prospect management dashboard<br>- GDPR & CCPA compliant | Pricing on website (not disclosed here)               | Sales, recruitment, founders, and B2B teams focused on Europe                | - Strong European market focus<br>- LinkedIn-integrated workflow for in-session contact retrieval<br>- CRM & sales tool ecosystem integration  |\n",
            "| **Dealfront** | - AI-driven pipeline creation<br>- ICP insights & Buyer Intent signals<br>- Browser extension<br>- Data cleansing & enrichment<br>- Targeted B2B ads<br>- Multiple modules (Datacare, Promote, Target, Connect)<br>- Integrations (Salesforce, HubSpot, Google Ads) | No public pricing; requires sales consultation             | Sales & marketing teams in B2B, especially Europe, seeking AI-powered insights & ads | - AI-powered intent scoring & segmentation<br>- Comprehensive revenue enablement modules including ads<br>- Strong CRM & ad platform integrations |\n",
            "| **Cognism**  | - Sales Companion workflow integration<br>- Buyer signals & insights<br>- Data-as-a-Service to warehouses<br>- Proprietary Diamond DataÂ® tech<br>- GDPR-compliant<br>- Broad GTM use cases<br>- Integrations | Pricing by consultation                    | Sales, Marketing, Revenue Ops in B2B worldwide                   | - Proprietary data tech ensuring top compliance & quality<br>- Large global customer base<br>- Comprehensive all-in-one intelligence & integration platform  |\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Competitorsâ€™ Strengths vs Lusha\n",
            "\n",
            "- **Kaspr**  \n",
            "  - Strong LinkedIn workflow integration allowing instant data extraction during LinkedIn prospecting (more seamless in-platform data retrieval vs Lusha's Chrome Extension which requires user interaction).  \n",
            "  - Focus on exhaustive verified contact data in Europe with strong compliance emphasis.  \n",
            "  - Bulk enrichment capabilities for lists enabling efficient lead list management.\n",
            "\n",
            "- **Dealfront**  \n",
            "  - Advanced AI tools for pipeline generation and ICP segmentation beyond contact data.  \n",
            "  - Diverse modular platform covering ads, visitor tracking, data cleansing in one suiteâ€”broader revenue enablement coverage.  \n",
            "  - Buyer intent signals combined with targeted B2B advertising capabilities, enabling more proactive multi-channel campaigns.\n",
            "\n",
            "- **Cognism**  \n",
            "  - Proprietary Diamond DataÂ® technology ensures very high quality and compliant data, especially robust for GDPR.  \n",
            "  - Data-as-a-Service delivery into customer warehousesâ€”better for enterprises needing embedded data for analytics across systems.  \n",
            "  - Large global reach and established enterprise footprint, trusted by thousands of companies worldwide.\n",
            "\n",
            "---\n",
            "\n",
            "### 3. Lushaâ€™s Competitive Advantages\n",
            "\n",
            "- **Real-time AI-driven buyer intent and lead streaming** keeps prospect playlists fresh and actionable, enabling revenue teams to prioritize hottest leads.  \n",
            "- **Comprehensive automation** tools (including email personalization and sales meeting analysis) help accelerate outreach and pipeline velocity beyond raw data access.  \n",
            "- **Multi-channel prospecting suite** with Chrome extension and API-based integrations suits a wide variety of workflows, from manual social selling to automated CRM enrichment.  \n",
            "- Flexible and transparent pricing options with a free tier and custom scaling make it accessible to SMBs and large enterprises alike.  \n",
            "- Strong reputation for ease-of-use and effectiveness in pipeline acceleration, widely rated by users.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. Areas Where Lusha Could Improve\n",
            "\n",
            "- **Data Volume & European Market Depth:** Kaspr and Dealfront emphasize strong verified European contact databases and compliance. Lusha could enhance verification and data quantity depth specifically in European markets to compete more aggressively.  \n",
            "- **Modular Revenue Suite:** Dealfrontâ€™s multi-module approach (ads, ICP insights, data cleansing) provides end-to-end revenue enablement vs Lushaâ€™s primarily lead and intent focus. Lusha could expand additional modules to cover broader campaign execution or data hygiene features.  \n",
            "- **Bulk Data Enrichment at Scale:** Kaspr offers extensive bulk enrichment and list management. Lusha can improve bulk data processing capabilities and more advanced prospect list workflows inside the platform.  \n",
            "- **Deeper Embedded Analytics & Data Delivery:** Cognismâ€™s Data-as-a-Service and warehouse integration is attractive for enterprises needing tight control over data pipelines. Lusha could develop enhanced enterprise-grade APIs and direct data delivery options for embedding intelligence into broader BI systems.  \n",
            "- **Pricing Transparency and Customization:** While flexible, Lusha's pricing details require user inquiry beyond free tier. Providing more transparent mid-market pricing tiers online could improve user confidence and conversion.\n",
            "\n",
            "---\n",
            "\n",
            "**Summary:** Lusha leads with AI-driven intent signals, automation, and multi-channel prospecting ease, serving a broad audience from SMB to enterprise. However, competitors Kaspr and Dealfront outshine Lusha in Europe-focused verified data and broader revenue enablement modules, while Cognism excels in data quality and enterprise-grade integrations. Lusha should deepen European data depth, diversify modular features (ads, cleansing), and enhance bulk enrichment and embedded data delivery to close these gaps.\n"
          ]
        }
      ],
      "source": [
        "# Execute: Generate competitive comparison of all companies\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"COMPETITIVE COMPARISON\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "profiles_summary = json.dumps(company_profiles, indent=2)\n",
        "\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"\"\"Compare these companies against {MY_BRAND}. Create a competitive analysis:\n",
        "1. Comparison table (features, pricing, target market)\n",
        "2. Each competitor's strengths vs {MY_BRAND}\n",
        "3. {MY_BRAND}'s competitive advantages\n",
        "4. Areas where {MY_BRAND} could improve\n",
        "\n",
        "Be direct and actionable.\"\"\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Company profiles:\\n{profiles_summary}\"\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=1500\n",
        ")\n",
        "\n",
        "comparison_analysis = response.choices[0].message.content\n",
        "print(comparison_analysis)\n",
        "\n",
        "# Store for executive summary\n",
        "deep_insights = {\n",
        "    'company_profiles': company_profiles,\n",
        "    'comparison': comparison_analysis\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0RrDIXDdIO3"
      },
      "source": [
        "---\n",
        "## Section 5: Executive Summary\n",
        "\n",
        "This section compiles all findings into a comprehensive competitive intelligence report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQmU2hHFdIO3",
        "outputId": "d050cb7a-f0c0-4767-944f-3a71f7d8975d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executive summary data compiled.\n",
            "\n",
            "Sections included:\n",
            "  - SERP Rankings: 3 keywords\n",
            "  - AI Perception: 9/12 mentions\n",
            "  - Competitor Insights: 4 pages\n",
            "  - Company Profiles: 4 companies\n"
          ]
        }
      ],
      "source": [
        "# Execute: Compile all data into a summary structure\n",
        "\n",
        "executive_summary = {\n",
        "    'brand': MY_BRAND,\n",
        "    'domain': MY_DOMAIN,\n",
        "    'market': COUNTRY,\n",
        "    'generated_at': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "\n",
        "    # SERP Rankings\n",
        "    'serp': {\n",
        "        'keywords_tracked': len(rankings['keywords']),\n",
        "        'rankings': {kw: data['my_position'] for kw, data in rankings['keywords'].items()},\n",
        "        'main_competitors': [c['domain'] for c in rankings['main_competitors'][:3]]\n",
        "    },\n",
        "\n",
        "    # AI Perception\n",
        "    'ai_perception': {\n",
        "        'engines_queried': [r['engine_name'] for r in ai_results],\n",
        "        'mentions': sum(1 for r in ai_results if r.get('mentioned')),\n",
        "        'total_queries': len(ai_results)\n",
        "    },\n",
        "\n",
        "    # Competitor Insights\n",
        "    'competitor_insights': competitor_insights,\n",
        "\n",
        "    # Deep Analysis (now contains company_profiles and comparison)\n",
        "    'deep_insights': deep_insights\n",
        "}\n",
        "\n",
        "print(\"Executive summary data compiled.\")\n",
        "print(f\"\\nSections included:\")\n",
        "print(f\"  - SERP Rankings: {executive_summary['serp']['keywords_tracked']} keywords\")\n",
        "print(f\"  - AI Perception: {executive_summary['ai_perception']['mentions']}/{executive_summary['ai_perception']['total_queries']} mentions\")\n",
        "print(f\"  - Competitor Insights: {len(competitor_insights)} pages\")\n",
        "print(f\"  - Company Profiles: {len(deep_insights.get('company_profiles', []))} companies\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY2aagZEdIO3",
        "outputId": "ded8e5ae-3399-4e41-e0d8-5ad52fa8f65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating executive report with GPT...\n",
            "\n",
            "============================================================\n",
            "EXECUTIVE REPORT: Lusha\n",
            "Generated: 2026-01-14 14:59:05\n",
            "============================================================\n",
            "\n",
            "Executive Competitive Intelligence Report: Lusha\n",
            "\n",
            "1. Overall Competitive Position\n",
            "Lusha holds a credible position as an AI-powered sales intelligence platform but currently lacks prominent visibility in key SERP rankings such as \"lead generation software\" and \"B2B contact database,\" limiting its market discoverability relative to competitors.\n",
            "\n",
            "2. Key Strengths\n",
            "- Offers AI-enhanced B2B data enriched with real-time buying signals and AI workflows, supporting accelerated pipeline growth.\n",
            "- Flexible pricing models including free starter options and customizable enterprise plans cater to a broad customer base.\n",
            "- Mentioned in the majority of AI-related search queries, enhancing technological thought leadership perception.\n",
            "\n",
            "3. Areas for Improvement\n",
            "- Suboptimal search engine ranking in critical keywords diminishes organic lead generation and brand exposure.\n",
            "- Pricing transparency is moderate; enterprise plans require sales engagement which may deter self-service buyers.\n",
            "- Competitive differentiation versus rivals like Kaspr and Dealfront is not distinctly pronounced in marketing messaging.\n",
            "\n",
            "4. Top 3 Recommended Actions\n",
            "- Invest in targeted SEO campaigns focused on high-value keywords (\"lead generation software,\" \"B2B contact database,\" \"sales prospecting tool\") to improve top-10 SERP rankings.\n",
            "- Enhance website content clarity on pricing structures and value propositions to streamline buyer decision-making and reduce friction.\n",
            "- Amplify unique AI workflow capabilities and real-time signal benefits through case studies and comparative marketing to differentiate from competitors effectively.\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Execute: GPT generates comprehensive executive report\n",
        "\n",
        "if openai_client:\n",
        "    print(\"Generating executive report with GPT...\\n\")\n",
        "\n",
        "    # Build context from all sections\n",
        "    full_context = f\"\"\"\n",
        "COMPETITIVE INTELLIGENCE REPORT\n",
        "Brand: {MY_BRAND}\n",
        "Domain: {MY_DOMAIN}\n",
        "Market: {COUNTRY}\n",
        "\n",
        "=== SERP RANKINGS ===\n",
        "\"\"\"\n",
        "    for kw, data in rankings['keywords'].items():\n",
        "        pos = data['my_position'] or \"Not in top 10\"\n",
        "        full_context += f\"\\n'{kw}': Position {pos}\"\n",
        "\n",
        "    full_context += f\"\\n\\nMain Competitors: {', '.join(executive_summary['serp']['main_competitors'])}\"\n",
        "\n",
        "    full_context += \"\\n\\n=== AI PERCEPTION ===\"\n",
        "    full_context += f\"\\nMentioned in {executive_summary['ai_perception']['mentions']}/{executive_summary['ai_perception']['total_queries']} AI engine queries\"\n",
        "\n",
        "    full_context += \"\\n\\n=== COMPANY PROFILES ===\"\n",
        "    for profile in deep_insights.get('company_profiles', []):\n",
        "        label = \"(YOUR COMPANY)\" if profile.get('is_my_domain') else \"\"\n",
        "        full_context += f\"\\n{profile.get('domain', 'Unknown')} {label}\"\n",
        "        full_context += f\"\\n  Value prop: {profile.get('value_proposition', 'N/A')}\"\n",
        "        full_context += f\"\\n  Pricing: {profile.get('pricing', 'N/A')}\"\n",
        "\n",
        "    full_context += \"\\n\\n=== COMPETITIVE COMPARISON ===\"\n",
        "    full_context += f\"\\n{deep_insights.get('comparison', 'N/A')[:500]}...\"\n",
        "\n",
        "    # Generate executive report\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"You are a senior competitive intelligence analyst. Generate a concise executive report with:\n",
        "1. Overall competitive position (1-2 sentences)\n",
        "2. Key strengths (2-3 bullets)\n",
        "3. Areas for improvement (2-3 bullets)\n",
        "4. Top 3 recommended actions\n",
        "\n",
        "Be direct and actionable.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Generate an executive report based on this data:\\n{full_context}\"\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=2000\n",
        "    )\n",
        "\n",
        "    executive_report = response.choices[0].message.content\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(f\"EXECUTIVE REPORT: {MY_BRAND}\")\n",
        "    print(f\"Generated: {executive_summary['generated_at']}\")\n",
        "    print(\"=\"*60)\n",
        "    print()\n",
        "    print(executive_report)\n",
        "    print()\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"Skipping executive report (no OpenAI API key configured)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
