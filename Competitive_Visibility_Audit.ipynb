{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1tUL_fZdIOy"
   },
   "source": "# Competitive Visibility Audit\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ScrapeAlchemist/Competitive-Visibility-Audit/blob/main/Competitive_Visibility_Audit.ipynb)\n\nA competitive intelligence pipeline that uses Bright Data's Web Execution Layer APIs and OpenAI GPT for analysis.\n\nThis notebook performs a comprehensive competitive audit across 5 sections:\n\n1. **SERP Ranking** - Searches Google for industry keywords, finds your position vs competitors, and identifies top competitors\n2. **Deep Dive** - Scrapes competitor homepages as markdown and extracts value propositions, features, pricing, and trust signals using GPT\n3. **AI Perception** - Queries ChatGPT, Perplexity, Grok, and Gemini to see if AI engines recommend your brand\n4. **Deep Competitor Analysis** - Scrapes deeper pages (pricing, features) and generates consolidated company profiles with competitive comparison\n5. **Executive Summary** - GPT-powered analysis compiling all findings into actionable insights\n\n---\n\n### Prerequisites\n- Bright Data account with API access\n- SERP API zone configured\n- Web Unlocker zone configured\n- OpenAI API key"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuBIUu9ldIOz"
   },
   "source": [
    "## Section 0: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ez3wV9XgdIOz"
   },
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "# - requests: For making HTTP calls to Bright Data APIs\n",
    "# - openai: For GPT-powered keyword generation and analysis\n",
    "!pip install -q requests openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwHmJaDJdIOz",
    "outputId": "454f2edf-a9a4-4250-aff3-3f439c2a58c7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Configuration loaded:\n",
      "  Brand: wix\n",
      "  Domain: wix.com\n",
      "  Country: us\n",
      "  Bright Data API: âœ“ configured\n",
      "  OpenAI API: âœ“ configured\n"
     ]
    }
   ],
   "source": [
    "#@title ðŸ‘‰ Enter Your Company Details Here\n",
    "#@markdown ---\n",
    "#@markdown Enter your company information below, then run the rest of the notebook.\n",
    "#@markdown ---\n",
    "\n",
    "MY_BRAND = \"wix\" #@param {type:\"string\"}\n",
    "MY_DOMAIN = \"wix.com\" #@param {type:\"string\"}\n",
    "COUNTRY = \"us\" #@param {type:\"string\"}\n",
    "\n",
    "# ============================================\n",
    "# API credentials (from Colab secrets)\n",
    "# ============================================\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "os.environ['BRIGHTDATA_API_TOKEN'] = userdata.get('BRIGHTDATA_API_TOKEN')\n",
    "os.environ['BRIGHTDATA_ZONE_SERP'] = userdata.get('BRIGHTDATA_ZONE_SERP')\n",
    "os.environ['BRIGHTDATA_ZONE_UNLOCKER'] = userdata.get('BRIGHTDATA_ZONE_UNLOCKER')\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "BRIGHTDATA_API_TOKEN = os.environ.get(\"BRIGHTDATA_API_TOKEN\")\n",
    "BRIGHTDATA_ZONE_SERP = os.environ.get(\"BRIGHTDATA_ZONE_SERP\", \"serp_api1\")\n",
    "BRIGHTDATA_ZONE_UNLOCKER = os.environ.get(\"BRIGHTDATA_ZONE_UNLOCKER\", \"unlocker\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Brand: {MY_BRAND}\")\n",
    "print(f\"  Domain: {MY_DOMAIN}\")\n",
    "print(f\"  Country: {COUNTRY}\")\n",
    "print(f\"  Bright Data API: {'âœ“ configured' if BRIGHTDATA_API_TOKEN else 'âœ— missing'}\")\n",
    "print(f\"  OpenAI API: {'âœ“ configured' if OPENAI_API_KEY else 'âœ— missing'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hq1xc2CdIO0",
    "outputId": "8b02608e-04e4-4418-b7d0-e53d6e336e71"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating research keywords with GPT...\n",
      "\n",
      "GPT generated keywords:\n",
      "  - website builder\n",
      "  - create website online\n",
      "  - drag and drop website\n"
     ]
    }
   ],
   "source": [
    "# Execute: Use GPT to generate relevant keywords based on the brand/domain\n",
    "\n",
    "print(\"Generating research keywords with GPT...\\n\")\n",
    "\n",
    "# Retry initializing OpenAI client if it's None\n",
    "if openai_client is None and OPENAI_API_KEY:\n",
    "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(\"Retried OpenAI client initialization...\")\n",
    "\n",
    "if openai_client:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a competitive intelligence expert. Given a brand and domain, generate 3 search keywords that potential customers would use to find this type of product/service.\n",
    "\n",
    "Return ONLY valid JSON in this exact format, no other text:\n",
    "{\"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]}\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Brand: {MY_BRAND}\\nDomain: {MY_DOMAIN}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        generated = json.loads(response.choices[0].message.content)\n",
    "        keywords_list = generated['keywords']\n",
    "        print(\"GPT generated keywords:\")\n",
    "        for kw in keywords_list:\n",
    "            print(f\"  - {kw}\")\n",
    "    except:\n",
    "        keywords_list = [f\"{MY_BRAND} alternatives\", f\"best {MY_DOMAIN.split('.')[0]} tools\"]\n",
    "        print(f\"Using fallback keywords: {keywords_list}\")\n",
    "else:\n",
    "    keywords_list = [MY_BRAND, f\"{MY_BRAND} review\", f\"{MY_BRAND} alternatives\"]\n",
    "    print(f\"No OpenAI API key - using fallback keywords: {keywords_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ66n4LQdIO0"
   },
   "source": [
    "---\n",
    "## Section 1: SERP Ranking\n",
    "\n",
    "In this section, we'll use Bright Data's SERP API to:\n",
    "1. Search Google for your target keywords\n",
    "2. Find where YOUR domain ranks in the results\n",
    "3. Identify your main competitors\n",
    "\n",
    "### How the SERP API Works\n",
    "The SERP API sends requests through Bright Data's proxy network and returns structured JSON data from Google search results. The `brd_json=1` parameter tells the API to parse the HTML and return clean JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RdwpDhXdIO0",
    "outputId": "1a973ec8-3cf6-4e95-e362-d849eb333efc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ“ search_keyword() function defined\n"
     ]
    }
   ],
   "source": [
    "# Setup: Define function to search Google via SERP API\n",
    "\n",
    "def search_keyword(keyword, country):\n",
    "    \"\"\"\n",
    "    Search Google for a keyword and return structured results.\n",
    "    \"\"\"\n",
    "    search_url = f\"https://www.google.com/search?q={requests.utils.quote(keyword)}&gl={country}&brd_json=1\"\n",
    "\n",
    "    print(f\"  Searching: {keyword}...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.brightdata.com/request\",\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            json={\n",
    "                \"zone\": BRIGHTDATA_ZONE_SERP,\n",
    "                \"url\": search_url,\n",
    "                \"format\": \"raw\"\n",
    "            },\n",
    "            timeout=60\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"    âœ— Error: {response.status_code} - {response.text[:100]}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Exception: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ“ search_keyword() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pBEjYQpdIO0",
    "outputId": "dc8e23ad-7f49-470d-be54-98c224b9bfcf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searching 3 keywords in us...\n",
      "\n",
      "  Searching: website builder...\n",
      "  Searching: create website online...\n",
      "  Searching: drag and drop website...\n",
      "    âœ“ 'drag and drop website': Found 9 organic results\n",
      "    âœ“ 'create website online': Found 9 organic results\n",
      "    âœ“ 'website builder': Found 9 organic results\n",
      "\n",
      "âœ“ Completed 3/3 searches\n"
     ]
    }
   ],
   "source": [
    "# Execute: Run SERP searches for all keywords in parallel\n",
    "\n",
    "print(f\"Searching {len(keywords_list)} keywords in {COUNTRY}...\\n\")\n",
    "\n",
    "serp_results = {}\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {}\n",
    "    for keyword in keywords_list:\n",
    "        future = executor.submit(search_keyword, keyword, COUNTRY)\n",
    "        futures[future] = keyword\n",
    "        time.sleep(0.05)  # 50ms delay between API calls\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        keyword = futures[future]\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            serp_results[keyword] = result\n",
    "            organic_count = len(result.get('organic', []))\n",
    "            print(f\"    âœ“ '{keyword}': Found {organic_count} organic results\")\n",
    "        else:\n",
    "            print(f\"    âœ— '{keyword}': No results\")\n",
    "\n",
    "print(f\"\\nâœ“ Completed {len(serp_results)}/{len(keywords_list)} searches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NVZHGuXdIO1",
    "outputId": "406eda1f-5182-4a2a-eb7d-a60ab953c38a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ“ extract_domain() function defined\n"
     ]
    }
   ],
   "source": [
    "# Setup: Define helper function to extract domain from URL\n",
    "\n",
    "def extract_domain(url):\n",
    "    \"\"\"Extract the root domain from a URL.\"\"\"\n",
    "    try:\n",
    "        from urllib.parse import urlparse\n",
    "        parsed = urlparse(url)\n",
    "        domain = parsed.netloc.lower()\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "        return domain\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"âœ“ extract_domain() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFSJ1nopdIO1",
    "outputId": "57c16351-d420-4b1c-8a4d-fc4755bc4509"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing rankings for wix.com...\n",
      "\n",
      "'drag and drop website': #3\n",
      "'create website online': #3\n",
      "'website builder': #7\n",
      "\n",
      "âœ“ Analyzed 3 keywords\n",
      "âœ“ Found 18 unique competitor domains\n"
     ]
    }
   ],
   "source": [
    "# Execute: Analyze SERP results to find YOUR ranking\n",
    "# This cell processes the raw SERP data to extract:\n",
    "# - Your brand's position for each keyword\n",
    "# - List of competitors and their positions\n",
    "# - Frequency count of competitors across all keywords\n",
    "\n",
    "# Initialize rankings dictionary to store all analysis results\n",
    "rankings = {\n",
    "    'brand': MY_BRAND,\n",
    "    'domain': MY_DOMAIN,\n",
    "    'country': COUNTRY,\n",
    "    'keywords': {},           # Per-keyword ranking data\n",
    "    'all_competitors': {},    # Competitor frequency across all keywords\n",
    "    'main_competitors': []    # Top competitors (set in next cell)\n",
    "}\n",
    "\n",
    "print(f\"Analyzing rankings for {MY_DOMAIN}...\\n\")\n",
    "\n",
    "# Loop through each keyword's SERP results\n",
    "for keyword, data in serp_results.items():\n",
    "    # Get organic (non-ad) search results\n",
    "    organic = data.get('organic', [])\n",
    "\n",
    "    my_position = None\n",
    "    competitors = []\n",
    "\n",
    "    # Check top 10 results for each keyword\n",
    "    for result in organic[:10]:\n",
    "        # Use the rank field directly from Bright Data's API response\n",
    "        rank = result.get('rank')\n",
    "        url = result.get('link', '')\n",
    "        domain = extract_domain(url)\n",
    "        title = result.get('title', '')\n",
    "\n",
    "        # Check if this result is OUR domain\n",
    "        if domain and MY_DOMAIN.lower() in domain:\n",
    "            my_position = rank\n",
    "        else:\n",
    "            # It's a competitor - add to list\n",
    "            competitors.append({\n",
    "                'position': rank,\n",
    "                'domain': domain,\n",
    "                'title': title\n",
    "            })\n",
    "            # Track how often each competitor appears across keywords\n",
    "            if domain:\n",
    "                rankings['all_competitors'][domain] = rankings['all_competitors'].get(domain, 0) + 1\n",
    "\n",
    "    # Store results for this keyword\n",
    "    rankings['keywords'][keyword] = {\n",
    "        'my_position': my_position,\n",
    "        'competitors': competitors[:5]  # Keep top 5 competitors per keyword\n",
    "    }\n",
    "\n",
    "    # Print summary for this keyword\n",
    "    position_str = f\"#{my_position}\" if my_position else \"Not in top 10\"\n",
    "    print(f\"'{keyword}': {position_str}\")\n",
    "\n",
    "print(f\"\\nâœ“ Analyzed {len(rankings['keywords'])} keywords\")\n",
    "print(f\"âœ“ Found {len(rankings['all_competitors'])} unique competitor domains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBZuYCNddIO1",
    "outputId": "690a5043-28bd-4ff8-8ad9-6b392aabe719"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================================\n",
      "MAIN COMPETITORS (by frequency across keywords):\n",
      "  canva.com: appears in 3 keyword(s)\n",
      "  weebly.com: appears in 2 keyword(s)\n",
      "  squarespace.com: appears in 2 keyword(s)\n",
      "  godaddy.com: appears in 2 keyword(s)\n",
      "  webflow.com: appears in 2 keyword(s)\n"
     ]
    }
   ],
   "source": [
    "# Execute: Identify main competitors by counting how many times each domain\n",
    "# appears across all keyword searches. Use GPT to filter out non-competitors\n",
    "# (forums, review sites, social media, etc.)\n",
    "\n",
    "# Get top 10 domains by frequency (we'll filter with GPT)\n",
    "candidate_competitors = sorted(\n",
    "    [(domain, count) for domain, count in rankings['all_competitors'].items()],\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "# Use GPT to filter out non-competitors\n",
    "if openai_client and candidate_competitors:\n",
    "    domains_list = [d[0] for d in candidate_competitors]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"You are analyzing search results for {MY_BRAND} ({MY_DOMAIN}).\n",
    "\n",
    "Given a list of domains, identify which are ACTUAL BUSINESS COMPETITORS (companies offering similar products/services).\n",
    "\n",
    "EXCLUDE: forums (reddit, quora), social media (linkedin, twitter, youtube), review sites (g2, capterra, trustpilot), news sites, Wikipedia, GitHub, Amazon, etc.\n",
    "\n",
    "Return ONLY a JSON array of competitor domains, no other text:\n",
    "[\"competitor1.com\", \"competitor2.com\"]\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Domains found in search results: {json.dumps(domains_list)}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        filtered_domains = json.loads(response.choices[0].message.content)\n",
    "        # Rebuild list with counts, preserving order\n",
    "        main_competitors = [(d, c) for d, c in candidate_competitors if d in filtered_domains][:5]\n",
    "    except:\n",
    "        # Fallback to original list if GPT parsing fails\n",
    "        main_competitors = candidate_competitors[:5]\n",
    "else:\n",
    "    main_competitors = candidate_competitors[:5]\n",
    "\n",
    "rankings['main_competitors'] = [{'domain': d, 'frequency': c} for d, c in main_competitors]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MAIN COMPETITORS (by frequency across keywords):\")\n",
    "for comp in main_competitors:\n",
    "    print(f\"  {comp[0]}: appears in {comp[1]} keyword(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2KGqrjKdIO1",
    "outputId": "5a9bf6ea-b1a4-4c7b-97f5-ce66601bd8ec"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "SERP RANKING SUMMARY: wix\n",
      "============================================================\n",
      "Keyword                        Position        Top Competitor\n",
      "------------------------------------------------------------\n",
      "drag and drop website          #3              showit.com\n",
      "create website online          #3              squarespace.com\n",
      "website builder                #7              canva.com\n",
      "\n",
      "------------------------------------------------------------\n",
      "Top competitors to watch:\n",
      "  1. canva.com\n",
      "  2. weebly.com\n",
      "  3. squarespace.com\n"
     ]
    }
   ],
   "source": [
    "# Display rankings summary table\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"SERP RANKING SUMMARY: {MY_BRAND}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Keyword':<30} {'Position':<15} {'Top Competitor'}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for keyword, data in rankings['keywords'].items():\n",
    "    pos = data['my_position']\n",
    "    position_str = f\"#{pos}\" if pos else \"Not ranked\"\n",
    "    top_comp = data['competitors'][0]['domain'] if data['competitors'] else \"N/A\"\n",
    "    print(f\"{keyword:<30} {position_str:<15} {top_comp}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Top competitors to watch:\")\n",
    "for i, comp in enumerate(rankings['main_competitors'][:3], 1):\n",
    "    print(f\"  {i}. {comp['domain']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jd0752_CdIO1",
    "outputId": "e49d2d59-59d6-4e07-9e5d-7bab35dcc788"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating GPT analysis of SERP results...\n",
      "\n",
      "GPT ANALYSIS:\n",
      "----------------------------------------\n",
      "- Wix holds strong positions (#3) for \"drag and drop website\" and \"create website online,\" indicating solid relevance and brand recognition in DIY website creation.\n",
      "- Ranking lower (#7) for the highly competitive \"website builder\" keyword suggests an opportunity to optimize content and backlink strategies to challenge top competitors like Canva.\n",
      "- Competitors Squarespace and Canva dominate top spots in broader and more commercial intent terms, signaling a need for Wix to differentiate its value proposition or target long-tail variations.\n"
     ]
    }
   ],
   "source": [
    "# Execute: GPT summarizes SERP findings\n",
    "\n",
    "if openai_client:\n",
    "    print(\"Generating GPT analysis of SERP results...\\n\")\n",
    "\n",
    "    serp_summary = f\"\"\"\n",
    "    Brand: {MY_BRAND}\n",
    "    Domain: {MY_DOMAIN}\n",
    "    Market: {COUNTRY}\n",
    "\n",
    "    Keyword Rankings:\n",
    "    \"\"\"\n",
    "    for kw, data in rankings['keywords'].items():\n",
    "        pos = data['my_position'] or \"Not in top 10\"\n",
    "        serp_summary += f\"\\n    - '{kw}': Position {pos}\"\n",
    "        if data['competitors']:\n",
    "            serp_summary += f\" (Top competitor: {data['competitors'][0]['domain']})\"\n",
    "\n",
    "    serp_summary += f\"\\n\\n    Main Competitors: {', '.join([c['domain'] for c in rankings['main_competitors'][:3]])}\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a competitive intelligence analyst. Provide brief, actionable insights based on SERP ranking data. Be concise - 3-4 bullet points max.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Analyze these SERP rankings and provide key insights:\\n{serp_summary}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    serp_analysis = response.choices[0].message.content\n",
    "    print(\"GPT ANALYSIS:\")\n",
    "    print(\"-\"*40)\n",
    "    print(serp_analysis)\n",
    "else:\n",
    "    serp_analysis = None\n",
    "    print(\"Skipping GPT analysis (no OpenAI API key configured)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHqIuCKxdIO1"
   },
   "source": [
    "---\n",
    "## Section 2: Deep Dive into Competitor Pages\n",
    "\n",
    "Now that we've identified the top competitors in our search results, let's scrape those pages and analyze their strategies.\n",
    "\n",
    "We'll use Bright Data's **Web Unlocker** to fetch **your domain and competitor pages** as clean markdown, then use GPT to extract competitive insights like:\n",
    "- Their main value proposition\n",
    "- Key features they highlight\n",
    "- Trust signals (testimonials, client logos, stats)\n",
    "- Pricing transparency\n",
    "- Relevant URLs for deeper analysis (pricing pages, feature pages, etc.)\n",
    "\n",
    "This allows us to compare your messaging directly against your competitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usMdZoDxdIO1",
    "outputId": "e0f567f8-8f2d-4d6f-bb33-79e18c6dfb50"
   },
   "outputs": [],
   "source": "# Setup: Define function to scrape pages as markdown using Web Unlocker\n\ndef scrape_as_markdown(url, silent=False):\n    \"\"\"\n    Scrape a URL and return the content as clean markdown using Web Unlocker.\n    Set silent=True to suppress print output.\n    \"\"\"\n    if not silent:\n        print(f\"  Scraping: {url[:50]}...\")\n\n    try:\n        response = requests.post(\n            \"https://api.brightdata.com/request\",\n            headers={\n                \"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\",\n                \"Content-Type\": \"application/json\"\n            },\n            json={\n                \"zone\": BRIGHTDATA_ZONE_UNLOCKER,\n                \"url\": url,\n                \"format\": \"raw\",\n                \"data_format\": \"markdown\"\n            },\n            timeout=60\n        )\n\n        if response.status_code == 200:\n            markdown_content = response.text\n            if not silent:\n                print(f\"    âœ“ Got {len(markdown_content)} chars of markdown\")\n            return {'markdown': markdown_content[:10000], 'url': url}\n        else:\n            if not silent:\n                print(f\"    âœ— Error: {response.status_code}\")\n            return None\n\n    except Exception as e:\n        if not silent:\n            print(f\"    âœ— Error: {str(e)[:50]}\")\n        return None\n\nprint(\"âœ“ scrape_as_markdown() function defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qR401_mOdIO2",
    "outputId": "37b9aba9-1b58-459c-cf74-b0f4f92e0045"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selecting pages to analyze...\n",
      "\n",
      "  âœ“ Added our domain: https://wix.com\n",
      "  âœ“ Added competitor: https://canva.com\n",
      "  âœ“ Added competitor: https://weebly.com\n",
      "  âœ“ Added competitor: https://squarespace.com\n",
      "\n",
      "Selected 4 pages to deep-dive:\n",
      "  1. https://wix.com (YOUR DOMAIN)\n",
      "  2. https://canva.com \n",
      "  3. https://weebly.com \n",
      "  4. https://squarespace.com \n"
     ]
    }
   ],
   "source": [
    "# Execute: Select top competitor HOMEPAGES and our own domain to analyze\n",
    "\n",
    "print(\"Selecting pages to analyze...\\n\")\n",
    "\n",
    "competitor_urls = []\n",
    "\n",
    "# Add our own domain first for comparison\n",
    "my_url = f\"https://{MY_DOMAIN}\"\n",
    "competitor_urls.append(my_url)\n",
    "print(f\"  âœ“ Added our domain: {my_url}\")\n",
    "\n",
    "# Add top competitor homepages (not blog posts from SERP)\n",
    "for comp in rankings['main_competitors'][:3]:\n",
    "    domain = comp['domain']\n",
    "    url = f\"https://{domain}\"\n",
    "    if url not in competitor_urls:\n",
    "        competitor_urls.append(url)\n",
    "        print(f\"  âœ“ Added competitor: {url}\")\n",
    "\n",
    "print(f\"\\nSelected {len(competitor_urls)} pages to deep-dive:\")\n",
    "for i, url in enumerate(competitor_urls, 1):\n",
    "    label = \"(YOUR DOMAIN)\" if MY_DOMAIN.lower() in url.lower() else \"\"\n",
    "    print(f\"  {i}. {url} {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fn-kub5vdIO2",
    "outputId": "1fe2bea7-153f-4193-b053-5059e5ff9f97"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraping 4 pages...\n",
      "\n",
      "  Scraping: https://wix.com...\n",
      "  Scraping: https://canva.com...\n",
      "  Scraping: https://weebly.com...\n",
      "  Scraping: https://squarespace.com...\n",
      "    âœ“ Got 5645 chars of markdown\n",
      "    âœ“ https://weebly.com... \n",
      "    âœ“ Got 45320 chars of markdown\n",
      "    âœ“ https://squarespace.com... \n",
      "    âœ“ Got 26620 chars of markdown\n",
      "    âœ“ https://canva.com... \n",
      "    âœ“ Got 58112 chars of markdown\n",
      "    âœ“ https://wix.com... (YOUR DOMAIN)\n",
      "\n",
      "âœ“ Successfully scraped 4/4 pages\n"
     ]
    }
   ],
   "source": [
    "# Execute: Scrape the pages as markdown in parallel\n",
    "\n",
    "print(f\"Scraping {len(competitor_urls)} pages...\\n\")\n",
    "\n",
    "competitor_content = []\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {}\n",
    "    for url in competitor_urls:\n",
    "        future = executor.submit(scrape_as_markdown, url)\n",
    "        futures[future] = url\n",
    "        time.sleep(0.05)  # 50ms delay between API calls\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        url = futures[future]\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            label = \"(YOUR DOMAIN)\" if MY_DOMAIN in url else \"\"\n",
    "            print(f\"    âœ“ {url[:50]}... {label}\")\n",
    "            competitor_content.append(result)\n",
    "\n",
    "print(f\"\\nâœ“ Successfully scraped {len(competitor_content)}/{len(competitor_urls)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiZddM5udIO2",
    "outputId": "94404229-624f-4c1c-c078-311a4466e596"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing 4 pages with GPT in parallel...\n",
      "\n",
      "\n",
      "==================================================\n",
      "[YOUR DOMAIN] https://wix.com...\n",
      "==================================================\n",
      "{\n",
      "  \"value_proposition\": \"Create your site in minutes with the leading website builder featuring AI-powered tools and 2000+ customizable templates.\",\n",
      "  \"features\": [\n",
      "    \"AI website builder that creates a unique, business-ready website based on your description.\",\n",
      "    \"Access to over 2000 professionally designed, fully customizable website templates across multiple categories.\",\n",
      "    \"Comprehensive tools including eCommerce, scheduling, blogging, portfolio, domain registration, web hosting, SEO, and email marketing.\"\n",
      "  ],\n",
      "  \"target_audience\": \"Individuals, small businesses, entrepreneurs, freelancers, agencies, and enterprises seeking an easy, all-in-one platform to build, manage, and grow a professional website or online store without technical barriers.\",\n",
      "  \"pricing_info\": \"Pricing details are available via the dedicated pricing page at https://www.wix.com/plans; the platform offers a free start with no credit card required.\",\n",
      "  \"trust_signals\": \"No explicit testimonials or client logos found on the homepage; however, the mention of 'leading website builder' and showcasing a large variety of templates and professional solutions for agencies, developers, and enterprises imply strong market presence and credibility.\",\n",
      "  \"relevant_urls\": [\n",
      "    \"https://www.wix.com/plans\",\n",
      "    \"https://www.wix.com/website/templates\",\n",
      "    \"https://www.wix.com/ai-website-builder\",\n",
      "    \"https://www.wix.com/features/main\",\n",
      "    \"https://www.wix.com/studio\",\n",
      "    \"https://www.wix.com/support\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "[COMPETITOR] https://squarespace.com...\n",
      "==================================================\n",
      "{\n",
      "  \"value_proposition\": \"Squarespace is an all-in-one platform that makes it easy to create stunning websites and online stores, providing tools to grow your business and brand professionally.\",\n",
      "  \"features\": [\n",
      "    \"Comprehensive website design tools including AI Website Builder, customizable templates, portfolios, blogs, and analytics.\",\n",
      "    \"Integrated commerce capabilities such as ecommerce stores, invoicing, scheduling, memberships, donations, and financial solutions.\",\n",
      "    \"Marketing tools including SEO tools, email campaigns, and free tools to promote and grow your online presence.\"\n",
      "  ],\n",
      "  \"target_audience\": \"Entrepreneurs, creative professionals, small business owners, service providers, and nonprofits seeking an easy yet powerful platform to build websites, manage clients, and grow their businesses online.\",\n",
      "  \"pricing_info\": \"Pricing details are not explicitly shown on the homepage content but a 'Start a Free Trial' call to action indicates a subscription-based model with a starting free trial period.\",\n",
      "  \"trust_signals\": \"Showcases inspirational real user websites, offers 24/7 support via help center, active community forum, live webinars, and a network to hire experts; platform powers websites for diverse industries and professionals including photographers, consultants, educators, and nonprofits.\",\n",
      "  \"relevant_urls\": [\n",
      "    \"https://squarespace.com/pricing\",\n",
      "    \"https://squarespace.com/feature-index\",\n",
      "    \"https://squarespace.com/websites/ai-website-builder\",\n",
      "    \"https://squarespace.com/ecommerce-website\",\n",
      "    \"https://squarespace.com/solutions\",\n",
      "    \"https://support.squarespace.com\",\n",
      "    \"https://forum.squarespace.com\",\n",
      "    \"https://learning.squarespace.com\",\n",
      "    \"https://squarespace.com/designer/home\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "[COMPETITOR] https://weebly.com...\n",
      "==================================================\n",
      "{\n",
      "  \"value_proposition\": \"Build a free, customizable website or online store that grows with your business using Weebly\\u2019s powerful website builder.\",\n",
      "  \"features\": [\n",
      "    \"Access to customizable webpage designs and useful tools to build and grow your website.\",\n",
      "    \"All-in-one powerful eCommerce tools for order management, shipping, and payments, integrated with Square.\",\n",
      "    \"Step-by-step guidance, marketing tools like Facebook ads and automated email campaigns, and customer support via email, chat, or phone.\"\n",
      "  ],\n",
      "  \"target_audience\": \"Entrepreneurs, small business owners, and individuals seeking an easy-to-use platform to create websites and online stores to grow their business.\",\n",
      "  \"pricing_info\": \"Pricing information is accessible via the /pricing page but not detailed on this landing page; the core website builder is promoted as free.\",\n",
      "  \"trust_signals\": \"Part of the Square product suite, community events for entrepreneurs, helpful blog and inspiration center, and available customer success support.\",\n",
      "  \"relevant_urls\": [\n",
      "    \"https://weebly.com/pricing\",\n",
      "    \"https://weebly.com/features\",\n",
      "    \"https://weebly.com/websites\",\n",
      "    \"https://weebly.com/online-store\",\n",
      "    \"https://weebly.com/marketing\",\n",
      "    \"https://weebly.com/guides\",\n",
      "    \"https://weebly.com/blog\",\n",
      "    \"https://weebly.com/app-center\",\n",
      "    \"https://hc.weebly.com/hc/en-us\",\n",
      "    \"https://weebly.com/about\",\n",
      "    \"https://weebly.com/contact\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==================================================\n",
      "[COMPETITOR] https://canva.com...\n",
      "==================================================\n",
      "{\n",
      "  \"value_proposition\": \"Canva is a comprehensive visual suite that empowers everyone to create stunning digital and print designs with ease.\",\n",
      "  \"features\": [\n",
      "    \"Wide range of design tools including email, sheets, docs, whiteboards, presentations, social media, photo and video editors, print design, and website builder.\",\n",
      "    \"AI-powered features like AI image generator, AI photo editor, AI video and music generators, and AI assistant to enhance creativity and productivity.\",\n",
      "    \"Tailored solutions for business, education, nonprofits, and enterprise with collaboration, brand management, and productivity tools.\"\n",
      "  ],\n",
      "  \"target_audience\": \"Individuals, creatives, marketers, businesses, educators, nonprofits, and enterprises looking for versatile and easy-to-use design tools and brand management solutions.\",\n",
      "  \"pricing_info\": \"Multiple plans available including Pro, Business, Enterprise, Nonprofit, Education, and Higher Education; with a detailed pricing comparison page at https://www.canva.com/pricing/\",\n",
      "  \"trust_signals\": \"Not explicitly visible on the provided page content, but implied trust through extensive product offerings, specialized plans, demos, ROI calculator, onboarding services, and a partners directory.\",\n",
      "  \"relevant_urls\": [\n",
      "    \"https://www.canva.com/pricing/\",\n",
      "    \"https://www.canva.com/features/\",\n",
      "    \"https://www.canva.com/visual-suite/\",\n",
      "    \"https://www.canva.com/business/features/\",\n",
      "    \"https://www.canva.com/solutions/\",\n",
      "    \"https://www.canva.com/pro/\",\n",
      "    \"https://www.canva.com/canva-business/\",\n",
      "    \"https://www.canva.com/enterprise/\",\n",
      "    \"https://www.canva.com/nonprofits/\",\n",
      "    \"https://www.canva.com/education/\",\n",
      "    \"https://www.canva.com/for-campus/\",\n",
      "    \"https://www.canva.com/ai-assistant/\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "âœ“ Analyzed 4 pages\n"
     ]
    }
   ],
   "source": [
    "# Execute: GPT analyzes pages and extracts relevant URLs\n",
    "# This cell sends each scraped page to GPT for analysis.\n",
    "# GPT extracts structured insights and identifies deeper pages to scrape later.\n",
    "\n",
    "def analyze_page_with_gpt(page):\n",
    "    \"\"\"Analyze a single page with GPT and return insights.\"\"\"\n",
    "    is_my_domain = MY_DOMAIN in page['url']\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Analyze this page and extract:\n",
    "1. Main value proposition (1 sentence)\n",
    "2. Key features/benefits highlighted (2-3 bullets)\n",
    "3. Target audience signals\n",
    "4. Pricing info if visible\n",
    "5. Trust signals (testimonials, client logos, stats)\n",
    "6. Relevant URLs for deeper analysis, ordered by importance (pricing page first, then features, etc.)\n",
    "\n",
    "Return JSON format:\n",
    "{\n",
    "  \"value_proposition\": \"...\",\n",
    "  \"features\": [\"...\", \"...\"],\n",
    "  \"target_audience\": \"...\",\n",
    "  \"pricing_info\": \"...\",\n",
    "  \"trust_signals\": \"...\",\n",
    "  \"relevant_urls\": [\"https://...\", \"https://...\"]\n",
    "}\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"URL: {page['url']}\\n\\nPage Content:\\n{page['markdown'][:10000]}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        analysis = json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        analysis = {'raw': response.choices[0].message.content, 'relevant_urls': []}\n",
    "\n",
    "    return {\n",
    "        'url': page['url'],\n",
    "        'is_my_domain': is_my_domain,\n",
    "        'analysis': analysis\n",
    "    }\n",
    "\n",
    "if openai_client and competitor_content:\n",
    "    print(f\"Analyzing {len(competitor_content)} pages with GPT in parallel...\\n\")\n",
    "\n",
    "    competitor_insights = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(analyze_page_with_gpt, page): page for page in competitor_content}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            page = futures[future]\n",
    "            result = future.result()\n",
    "            competitor_insights.append(result)\n",
    "\n",
    "            # Display results\n",
    "            label = \"YOUR DOMAIN\" if result['is_my_domain'] else \"COMPETITOR\"\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"[{label}] {result['url'][:50]}...\")\n",
    "            print(f\"{'='*50}\")\n",
    "            print(json.dumps(result['analysis'], indent=2))\n",
    "\n",
    "    print(f\"\\nâœ“ Analyzed {len(competitor_insights)} pages\")\n",
    "else:\n",
    "    competitor_insights = []\n",
    "    print(\"No pages to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLnGrfRHdIO2"
   },
   "source": [
    "---\n",
    "## Section 3: AI Perception\n",
    "\n",
    "In this section, we'll query AI engines (ChatGPT, Perplexity, Grok, Gemini) to see:\n",
    "1. What they say when users ask about your industry\n",
    "2. Whether YOUR brand is mentioned in their responses\n",
    "3. How you compare to competitors in AI recommendations\n",
    "\n",
    "### How AI Engine Scraping Works\n",
    "Bright Data's Web Scraper API has pre-built endpoints for each AI engine. We send a prompt, and the API handles:\n",
    "- Opening the AI engine in a real browser\n",
    "- Submitting the prompt\n",
    "- Waiting for and extracting the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMpyNo7UdIO2",
    "outputId": "e739d538-2cc6-4901-8e3d-b3b669e12a5c"
   },
   "outputs": [],
   "source": "# AI Engine configuration\n\n# Number of redundant requests per query (for faster response times)\nREDUNDANT_REQUESTS = 3\n\nAI_ENGINES = {\n    'chatgpt': {\n        'dataset_id': 'gd_m7aof0k82r803d5bjm',\n        'name': 'ChatGPT',\n        'url': 'https://chatgpt.com/'\n    },\n    'perplexity': {\n        'dataset_id': 'gd_m7dhdot1vw9a7gc1n',\n        'name': 'Perplexity',\n        'url': 'https://www.perplexity.ai'\n    },\n    'grok': {\n        'dataset_id': 'gd_m8ve0u141icu75ae74',\n        'name': 'Grok',\n        'url': 'https://grok.com/'\n    },\n    'gemini': {\n        'dataset_id': 'gd_mbz66arm2mf9cu856y',\n        'name': 'Gemini',\n        'url': 'https://gemini.google.com/'\n    }\n}\n\nprint(\"AI Engines configured:\")\nfor key, config in AI_ENGINES.items():\n    print(f\"  - {config['name']}\")\nprint(f\"\\nRedundancy: {REDUNDANT_REQUESTS}x requests per query\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GIYOPwLdIO2",
    "outputId": "8ed91234-7918-47f3-9b18-3dcecd0cccad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating AI perception queries with GPT...\n",
      "\n",
      "Generated queries (brand NOT mentioned):\n",
      "  - What are the top B2B contact databases for accurate lead information?\n",
      "  - Which sales prospecting tools provide verified business emails and phone numbers?\n",
      "  - Best lead generation software for improving B2B sales outreach?\n"
     ]
    }
   ],
   "source": [
    "# Execute: GPT generates GENERIC industry queries for AI engines\n",
    "# These queries should NOT mention our brand - we want to see if AI engines\n",
    "# naturally recommend us when users ask about the industry/problem space\n",
    "\n",
    "print(\"Generating AI perception queries with GPT...\\n\")\n",
    "\n",
    "if openai_client:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Generate 3 questions that potential customers would ask AI assistants when looking for this type of product/service.\n",
    "\n",
    "IMPORTANT: Do NOT mention the brand name in any query. These should be generic industry questions like:\n",
    "- \"What's the best B2B contact database?\"\n",
    "- \"Which sales prospecting tools are most accurate?\"\n",
    "- \"Best tools for finding business email addresses\"\n",
    "\n",
    "We want to see if AI engines naturally recommend the brand without being asked about it directly.\n",
    "\n",
    "Return ONLY valid JSON array, no other text:\n",
    "[\"query 1\", \"query 2\", \"query 3\"]\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Brand: {MY_BRAND}\\nDomain: {MY_DOMAIN}\\nIndustry keywords: {', '.join(keywords_list)}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        ai_queries = json.loads(response.choices[0].message.content)\n",
    "        print(\"Generated queries (brand NOT mentioned):\")\n",
    "        for q in ai_queries:\n",
    "            print(f\"  - {q}\")\n",
    "    except:\n",
    "        ai_queries = [f\"best {keywords_list[0]} tools\", \"best sales prospecting software\", \"most accurate B2B contact database\"]\n",
    "        print(f\"Using fallback queries: {ai_queries}\")\n",
    "else:\n",
    "    ai_queries = [f\"best {keywords_list[0]} tools\", \"best sales prospecting software\", \"most accurate B2B contact database\"]\n",
    "    print(f\"Using default queries: {ai_queries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7aliR3hdIO2",
    "outputId": "6452e4a5-f709-4890-faa1-a1e4cfe13b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ trigger_ai_query() function defined\n"
     ]
    }
   ],
   "source": [
    "# Setup: Define function to trigger AI engine query\n",
    "# This function sends a prompt to an AI engine and returns a snapshot_id.\n",
    "# The snapshot_id is used to poll for results in the next step.\n",
    "\n",
    "def trigger_ai_query(engine_key, prompt, country):\n",
    "    \"\"\"Step 1: Send prompt to AI engine, get snapshot_id back.\"\"\"\n",
    "    engine = AI_ENGINES[engine_key]\n",
    "\n",
    "    # Handle Gemini not supporting Israel\n",
    "    query_country = country.upper() if not (engine_key == 'gemini' and country.upper() == 'IL') else ''\n",
    "\n",
    "    try:\n",
    "        # Gemini uses different payload format (input wrapper)\n",
    "        if engine_key == 'gemini':\n",
    "            payload = {\n",
    "                \"input\": [{\n",
    "                    \"url\": engine['url'],\n",
    "                    \"prompt\": prompt,\n",
    "                    \"country\": query_country\n",
    "                }]\n",
    "            }\n",
    "        else:\n",
    "            # ChatGPT, Perplexity, Grok use array directly\n",
    "            payload = [{\n",
    "                \"url\": engine['url'],\n",
    "                \"prompt\": prompt,\n",
    "                \"country\": query_country\n",
    "            }]\n",
    "\n",
    "        response = requests.post(\n",
    "            f\"https://api.brightdata.com/datasets/v3/trigger?dataset_id={engine['dataset_id']}\",\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        )\n",
    "\n",
    "        # API returns 200 with snapshot_id on success\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            snapshot_id = data.get('snapshot_id')\n",
    "            if snapshot_id:\n",
    "                return snapshot_id\n",
    "            else:\n",
    "                print(f\"    âœ— {engine['name']}: No snapshot_id - {str(data)[:100]}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"    âœ— {engine['name']}: HTTP {response.status_code} - {response.text[:100]}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— {engine['name']}: {str(e)[:100]}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ“ trigger_ai_query() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "MLVMqWxxoUib",
    "outputId": "1d6209f7-5b32-4400-e5c7-34ce52ad774b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 4 engines Ã— 3 queries...\n",
      "(Using 3x redundancy for speed)\n",
      "\n",
      "Triggering AI engine requests...\n",
      "\n",
      "âœ“ Triggered 36 snapshot requests\n",
      "  (12 unique tasks Ã— 3 redundant requests each)\n"
     ]
    }
   ],
   "source": [
    "# Execute: Phase 1 - Trigger all AI engine requests in parallel\n",
    "\n",
    "engines_to_query = ['chatgpt', 'perplexity', 'grok', 'gemini']\n",
    "\n",
    "print(f\"Querying {len(engines_to_query)} engines Ã— {len(ai_queries)} queries...\")\n",
    "print(f\"(Using {REDUNDANT_REQUESTS}x redundancy for speed)\\n\")\n",
    "\n",
    "# Build list of all engine + query combinations\n",
    "all_tasks = [(engine, query) for query in ai_queries for engine in engines_to_query]\n",
    "\n",
    "print(\"Triggering AI engine requests...\")\n",
    "\n",
    "pending_snapshots = []  # List of (engine, query, snapshot_id)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    futures = {}\n",
    "    for engine, query in all_tasks:\n",
    "        # Send REDUNDANT_REQUESTS identical requests per task\n",
    "        for _ in range(REDUNDANT_REQUESTS):\n",
    "            future = executor.submit(trigger_ai_query, engine, query, COUNTRY)\n",
    "            futures[future] = (engine, query)\n",
    "            time.sleep(0.05)\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        engine, query = futures[future]\n",
    "        snapshot_id = future.result()\n",
    "        if snapshot_id:\n",
    "            pending_snapshots.append((engine, query, snapshot_id))\n",
    "\n",
    "print(f\"\\nâœ“ Triggered {len(pending_snapshots)} snapshot requests\")\n",
    "print(f\"  ({len(all_tasks)} unique tasks Ã— {REDUNDANT_REQUESTS} redundant requests each)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "LKGGlk4iobOT",
    "outputId": "ed5a5773-6ddf-43b5-a5b2-b8c23c238587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for snapshots to complete...\n",
      "(This may take 1-3 minutes)\n",
      "\n",
      "  ... 0/12 complete (2s elapsed)\n",
      "  ... 0/12 complete (9s elapsed)\n",
      "  âœ“ Perplexity: Which sales prospecting tools provi...\n",
      "  ... 1/12 complete (16s elapsed)\n",
      "  âœ“ Perplexity: Best lead generation software for i...\n",
      "  ... 2/12 complete (23s elapsed)\n",
      "  ... 2/12 complete (30s elapsed)\n",
      "  ... 2/12 complete (38s elapsed)\n",
      "  âœ“ Gemini: Best lead generation software for i...\n",
      "  âœ“ Grok: Which sales prospecting tools provi...\n",
      "  âœ“ Gemini: Which sales prospecting tools provi...\n",
      "  ... 5/12 complete (45s elapsed)\n",
      "  âœ“ Gemini: What are the top B2B contact databa...\n",
      "  âœ“ ChatGPT: What are the top B2B contact databa...\n",
      "  âœ“ Grok: Best lead generation software for i...\n",
      "  âœ“ Perplexity: What are the top B2B contact databa...\n",
      "  ... 9/12 complete (51s elapsed)\n",
      "  ... 9/12 complete (57s elapsed)\n",
      "  ... 9/12 complete (62s elapsed)\n",
      "  âœ“ ChatGPT: Which sales prospecting tools provi...\n",
      "  ... 10/12 complete (68s elapsed)\n",
      "  ... 10/12 complete (73s elapsed)\n",
      "  âœ“ ChatGPT: Best lead generation software for i...\n",
      "  ... 11/12 complete (78s elapsed)\n",
      "  âœ“ Grok: What are the top B2B contact databa...\n",
      "  ... 12/12 complete (83s elapsed)\n",
      "\n",
      "âœ“ All 12 tasks completed!\n",
      "\n",
      "âœ“ 12 snapshots ready for download\n"
     ]
    }
   ],
   "source": [
    "# Execute: Phase 2 - Poll snapshots until ready\n",
    "\n",
    "print(\"Waiting for snapshots to complete...\")\n",
    "print(\"(This may take 1-3 minutes)\\n\")\n",
    "\n",
    "ready_snapshots = []  # List of (engine, query, snapshot_id)\n",
    "max_wait = 180  # 3 minutes max\n",
    "start_time = time.time()\n",
    "\n",
    "# Track which (engine, query) pairs we've already got results for\n",
    "completed_tasks = set()\n",
    "\n",
    "while (time.time() - start_time) < max_wait:\n",
    "    # Check if we have all unique tasks completed\n",
    "    if len(completed_tasks) >= len(all_tasks):\n",
    "        print(f\"\\nâœ“ All {len(all_tasks)} tasks completed!\")\n",
    "        break\n",
    "\n",
    "    for engine, query, snapshot_id in pending_snapshots:\n",
    "        # Skip if we already have a result for this engine+query\n",
    "        if (engine, query) in completed_tasks:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"https://api.brightdata.com/datasets/v3/progress/{snapshot_id}\",\n",
    "                headers={\"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\"},\n",
    "                timeout=10\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                status = response.json().get('status')\n",
    "                if status == 'ready':\n",
    "                    ready_snapshots.append((engine, query, snapshot_id))\n",
    "                    completed_tasks.add((engine, query))\n",
    "                    print(f\"  âœ“ {AI_ENGINES[engine]['name']}: {query[:35]}...\")\n",
    "                elif status == 'failed':\n",
    "                    # Mark as completed so we don't keep checking\n",
    "                    completed_tasks.add((engine, query))\n",
    "                    print(f\"  âœ— {AI_ENGINES[engine]['name']}: {query[:35]}... (failed)\")\n",
    "        except:\n",
    "            pass  # Will retry on next loop\n",
    "\n",
    "    # Progress update\n",
    "    elapsed = int(time.time() - start_time)\n",
    "    print(f\"  ... {len(completed_tasks)}/{len(all_tasks)} complete ({elapsed}s elapsed)\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(f\"\\nâœ“ {len(ready_snapshots)} snapshots ready for download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyQWgA-YonCX",
    "outputId": "67acfe7d-b58e-4946-93a6-1b55853e4c13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading results...\n",
      "\n",
      "  âœ“ Grok: Which sales prospecting tools provi...\n",
      "  âœ“ Perplexity: Which sales prospecting tools provi...\n",
      "  âœ“ Gemini: Which sales prospecting tools provi...\n",
      "  âœ“ Gemini: What are the top B2B contact databa...\n",
      "  âœ“ Gemini: Best lead generation software for i...\n",
      "  âœ“ Perplexity: Best lead generation software for i...\n",
      "  âœ“ Grok: Best lead generation software for i...\n",
      "  âœ“ ChatGPT: Best lead generation software for i...\n",
      "  âœ“ Grok: What are the top B2B contact databa...\n",
      "  âœ“ ChatGPT: Which sales prospecting tools provi...\n",
      "  âœ“ Perplexity: What are the top B2B contact databa...\n",
      "  âœ“ ChatGPT: What are the top B2B contact databa...\n",
      "\n",
      "âœ“ Got 12/12 responses\n"
     ]
    }
   ],
   "source": [
    "# Execute: Phase 3 - Download results from ready snapshots (in parallel)\n",
    "\n",
    "print(\"Downloading results...\\n\")\n",
    "\n",
    "ai_results = []\n",
    "downloaded_tasks = set()\n",
    "\n",
    "def download_result(engine, query, snapshot_id):\n",
    "    \"\"\"Download a single snapshot result.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json\",\n",
    "            headers={\"Authorization\": f\"Bearer {BRIGHTDATA_API_TOKEN}\"},\n",
    "            timeout=30\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if isinstance(data, list) and len(data) > 0:\n",
    "                item = data[0]\n",
    "                # Extract the response in markdown\n",
    "                content = item.get('answer_text_markdown', '')\n",
    "                return {\n",
    "                    'engine': engine,\n",
    "                    'engine_name': AI_ENGINES[engine]['name'],\n",
    "                    'query': query,\n",
    "                    'content': content\n",
    "                }\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {}\n",
    "    for engine, query, snapshot_id in ready_snapshots:\n",
    "        # Skip duplicates (from redundancy)\n",
    "        if (engine, query) in downloaded_tasks:\n",
    "            continue\n",
    "        downloaded_tasks.add((engine, query))\n",
    "\n",
    "        future = executor.submit(download_result, engine, query, snapshot_id)\n",
    "        futures[future] = (engine, query)\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        engine, query = futures[future]\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            ai_results.append(result)\n",
    "            print(f\"  âœ“ {AI_ENGINES[engine]['name']}: {query[:35]}...\")\n",
    "\n",
    "print(f\"\\nâœ“ Got {len(ai_results)}/{len(all_tasks)} responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVEDC4MPdIO2",
    "outputId": "8510dca7-99bb-412c-9c8b-58623bde5460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ check_brand_mention() function defined\n"
     ]
    }
   ],
   "source": [
    "# Setup: Define function to check brand mentions using LLM\n",
    "\n",
    "def check_brand_mention(text, brand):\n",
    "    \"\"\"Use LLM to check if brand is mentioned and extract position if listed.\"\"\"\n",
    "    if not text or not openai_client:\n",
    "        return {'mentioned': False, 'position': None}\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"Check if \\\"{brand}\\\" is mentioned in the text. Account for spelling variations.\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{{\"mentioned\": true/false, \"position\": null or number if in a ranked list}}\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text[:5000]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return {'mentioned': False, 'position': None}\n",
    "\n",
    "print(\"âœ“ check_brand_mention() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwX6Xb8xdIO2",
    "outputId": "872a3613-3548-4dad-b952-f67a89347f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 12 responses for 'Lusha' mentions...\n",
      "\n",
      "[Grok] What are the top B2B contact databa...\n",
      "  âœ“ MENTIONED (#5)\n",
      "\n",
      "[Gemini] Which sales prospecting tools provi...\n",
      "  âœ“ MENTIONED (#3)\n",
      "\n",
      "[Perplexity] Which sales prospecting tools provi...\n",
      "  âœ— Not mentioned\n",
      "\n",
      "[ChatGPT] Which sales prospecting tools provi...\n",
      "  âœ“ MENTIONED (#2)\n",
      "\n",
      "[Perplexity] Best lead generation software for i...\n",
      "  âœ— Not mentioned\n",
      "\n",
      "[Gemini] What are the top B2B contact databa...\n",
      "  âœ“ MENTIONED (#4)\n",
      "\n",
      "[Grok] Which sales prospecting tools provi...\n",
      "  âœ“ MENTIONED (#4)\n",
      "\n",
      "[ChatGPT] Best lead generation software for i...\n",
      "  âœ“ MENTIONED (#9)\n",
      "\n",
      "[ChatGPT] What are the top B2B contact databa...\n",
      "  âœ“ MENTIONED (#3)\n",
      "\n",
      "[Grok] Best lead generation software for i...\n",
      "  âœ“ MENTIONED (#3)\n",
      "\n",
      "[Perplexity] What are the top B2B contact databa...\n",
      "  âœ“ MENTIONED (#3)\n",
      "\n",
      "[Gemini] Best lead generation software for i...\n",
      "  âœ— Not mentioned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute: Check each AI response for brand mentions\n",
    "\n",
    "print(f\"Checking {len(ai_results)} responses for '{MY_BRAND}' mentions...\\n\")\n",
    "\n",
    "for result in ai_results:\n",
    "    mention = check_brand_mention(result['content'], MY_BRAND)\n",
    "    result['mentioned'] = mention['mentioned']\n",
    "    result['position'] = mention['position']\n",
    "\n",
    "    status = \"âœ“ MENTIONED\" if mention['mentioned'] else \"âœ— Not mentioned\"\n",
    "    pos = f\" (#{mention['position']})\" if mention['position'] else \"\"\n",
    "    print(f\"[{result['engine_name']}] {result['query'][:35]}...\")\n",
    "    print(f\"  {status}{pos}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PdnC5GXEdIO2",
    "outputId": "e4dba204-ee48-4f4e-cd12-1ac2e4c7420f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GPT analysis of AI perception...\n",
      "\n",
      "GPT ANALYSIS:\n",
      "----------------------------------------\n",
      "- Lusha has consistent visibility across multiple AI engines (Grok, Gemini, ChatGPT, Perplexity) for queries related to B2B contact databases and sales prospecting tools, often ranking within the top 5 results.\n",
      "- ChatGPT and Gemini position Lusha highly (positions #2 to #4), indicating strong recommendation strength on these platforms.\n",
      "- Perplexity shows mixed visibility, mentioning Lusha for B2B contact databases but not for lead generation or sales prospecting in certain queries, signaling some inconsistency.\n",
      "- Overall, Lusha is recognized and recommended by most AI engines but could improve presence in specific lead generation software queries, particularly on platforms like Perplexity and Gemini.\n"
     ]
    }
   ],
   "source": [
    "# Execute: GPT summarizes AI perception findings\n",
    "\n",
    "if openai_client and ai_results:\n",
    "    print(\"Generating GPT analysis of AI perception...\\n\")\n",
    "\n",
    "    # Build summary of all AI engine responses for GPT to analyze\n",
    "    ai_summary = f\"Brand: {MY_BRAND}\\n\\nAI Engine Responses:\\n\"\n",
    "    for r in ai_results:\n",
    "        mention_str = \"Mentioned\" if r['mentioned'] else \"Not mentioned\"\n",
    "        ai_summary += f\"\\n- [{r['engine_name']}] Query: '{r['query'][:40]}...'\\n\"\n",
    "        ai_summary += f\"  Result: {mention_str}\\n\"\n",
    "        if r.get('position'):\n",
    "            ai_summary += f\"  Position: #{r['position']}\\n\"\n",
    "\n",
    "    # Ask GPT-5 to analyze brand visibility across AI engines\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a brand visibility analyst. Analyze how AI engines perceive and recommend brands. Be concise - 3-4 bullet points max.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Analyze this brand's visibility across AI engines:\\n{ai_summary}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Store and display the analysis\n",
    "    ai_analysis = response.choices[0].message.content\n",
    "    print(\"GPT ANALYSIS:\")\n",
    "    print(\"-\"*40)\n",
    "    print(ai_analysis)\n",
    "else:\n",
    "    ai_analysis = None\n",
    "    print(\"Skipping GPT analysis (no OpenAI API key or no results)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtqJ3wShdIO3"
   },
   "source": [
    "---\n",
    "## Section 4: Deep Competitor Analysis\n",
    "\n",
    "In this section, we'll go deeper into competitor websites by:\n",
    "1. Using the URLs extracted in Section 2 (pricing pages, feature pages, etc.)\n",
    "2. Scraping those deeper pages\n",
    "3. Analyzing pricing, features, and messaging with GPT\n",
    "\n",
    "### Approach\n",
    "We'll use Bright Data's Web Unlocker API to scrape the relevant pages identified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygJ_sufAdIO3",
    "outputId": "9b61f477-31ac-42d9-f8d7-f2de1c707ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ cognism.com \n",
      "  âœ“ dealfront.com \n",
      "  âœ“ kaspr.io \n",
      "  âœ“ lusha.com (YOUR DOMAIN)\n",
      "\n",
      "Scraping deeper pages in parallel...\n",
      "  Collected: 20 pages\n",
      "âœ“ Done\n"
     ]
    }
   ],
   "source": [
    "# Execute: Scrape deeper pages (pricing, features, etc.) from URLs extracted in Section 2\n",
    "# Get up to 5 deeper URLs per domain (your domain + top 3 competitors)\n",
    "# Only scrape URLs that match the source domain\n",
    "\n",
    "deep_urls = []\n",
    "\n",
    "# Collect relevant URLs per domain (up to 5 each, must match source domain)\n",
    "for insight in competitor_insights:\n",
    "    urls = insight.get('analysis', {}).get('relevant_urls', [])\n",
    "    source_domain = extract_domain(insight['url'])\n",
    "    label = \"(YOUR DOMAIN)\" if insight.get('is_my_domain') else \"\"\n",
    "\n",
    "    # Add up to 5 URLs that match the source domain\n",
    "    count = 0\n",
    "    for url in urls:\n",
    "        url_domain = extract_domain(url)\n",
    "        # Only include URLs from the same domain\n",
    "        if url_domain and source_domain and source_domain in url_domain:\n",
    "            if url not in deep_urls and count < 5:\n",
    "                deep_urls.append(url)\n",
    "                count += 1\n",
    "\n",
    "    if count > 0:\n",
    "        print(f\"  âœ“ {source_domain} {label}\")\n",
    "\n",
    "print(f\"\\nScraping deeper pages in parallel...\")\n",
    "\n",
    "deep_content = []\n",
    "\n",
    "# Scrape all URLs in parallel\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {}\n",
    "    for url in deep_urls:\n",
    "        future = executor.submit(scrape_as_markdown, url, silent=True)\n",
    "        futures[future] = url\n",
    "        time.sleep(0.05)  # 50ms delay between API calls\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            deep_content.append(result)\n",
    "            print(f\"\\r  Collected: {len(deep_content)} pages\", end=\"\", flush=True)\n",
    "\n",
    "print(f\"\\nâœ“ Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9Jf49YVdIO3",
    "outputId": "0b26629d-a98c-4f7e-c132-cd40e6cafca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped pages into 4 companies:\n",
      "  - dealfront.com: 6 pages \n",
      "  - kaspr.io: 6 pages \n",
      "  - cognism.com: 6 pages \n",
      "  - lusha.com: 6 pages (YOUR COMPANY)\n"
     ]
    }
   ],
   "source": [
    "# Setup: Group all scraped pages by company domain\n",
    "# Combines homepage content with deeper pages (pricing, features, etc.)\n",
    "\n",
    "company_content = {}\n",
    "\n",
    "# Add homepage content from competitor_content\n",
    "for page in competitor_content:\n",
    "    domain = extract_domain(page['url'])\n",
    "    if domain not in company_content:\n",
    "        company_content[domain] = {\n",
    "            'is_my_domain': MY_DOMAIN.lower() in domain,\n",
    "            'pages': []\n",
    "        }\n",
    "    company_content[domain]['pages'].append(page)\n",
    "\n",
    "# Add deep page content\n",
    "for page in deep_content:\n",
    "    domain = extract_domain(page['url'])\n",
    "    if domain in company_content:\n",
    "        company_content[domain]['pages'].append(page)\n",
    "\n",
    "print(f\"Grouped pages into {len(company_content)} companies:\")\n",
    "for domain, data in company_content.items():\n",
    "    label = \"(YOUR COMPANY)\" if data['is_my_domain'] else \"\"\n",
    "    print(f\"  - {domain}: {len(data['pages'])} pages {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NULK9oPxopo",
    "outputId": "25a652e4-0441-47df-e2d8-9c8ef40ff72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating company profiles...\n",
      "\n",
      "âœ“ [COMPETITOR] kaspr.io\n",
      "âœ“ [COMPETITOR] dealfront.com\n",
      "âœ“ [YOUR COMPANY] lusha.com\n",
      "âœ“ [COMPETITOR] cognism.com\n",
      "\n",
      "âœ“ Generated 4 company profiles\n"
     ]
    }
   ],
   "source": [
    "# Execute: Generate consolidated profile for each company\n",
    "\n",
    "def analyze_company(domain, data):\n",
    "    \"\"\"Analyze all pages from a company and return a consolidated profile.\"\"\"\n",
    "    combined_content = \"\"\n",
    "    for page in data['pages']:\n",
    "        combined_content += f\"\\n\\n--- {page['url']} ---\\n{page['markdown'][:5000]}\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Analyze all pages from this company and create a consolidated profile.\n",
    "\n",
    "Return JSON format:\n",
    "{\n",
    "  \"company\": \"...\",\n",
    "  \"value_proposition\": \"1-2 sentences\",\n",
    "  \"features\": [\"feature 1\", \"feature 2\", \"feature 3\"],\n",
    "  \"pricing\": \"pricing details or 'Not available'\",\n",
    "  \"target_audience\": \"...\",\n",
    "  \"differentiators\": [\"diff 1\", \"diff 2\"]\n",
    "}\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Domain: {domain}\\n\\nPages:\\n{combined_content[:15000]}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        profile = json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        profile = {'raw': response.choices[0].message.content}\n",
    "\n",
    "    profile['domain'] = domain\n",
    "    profile['is_my_domain'] = data['is_my_domain']\n",
    "    return profile\n",
    "\n",
    "# Analyze all companies in parallel\n",
    "print(\"Generating company profiles...\\n\")\n",
    "company_profiles = []\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(analyze_company, domain, data): domain for domain, data in company_content.items()}\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        domain = futures[future]\n",
    "        profile = future.result()\n",
    "        company_profiles.append(profile)\n",
    "\n",
    "        label = \"YOUR COMPANY\" if profile['is_my_domain'] else \"COMPETITOR\"\n",
    "        print(f\"âœ“ [{label}] {domain}\")\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(company_profiles)} company profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBfFEQ9Gxopp",
    "outputId": "66a91e0b-e47f-4db4-cb33-b7f1a9fa82cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "[COMPETITOR] kaspr.io\n",
      "==================================================\n",
      "{\n",
      "  \"company\": \"Kaspr\",\n",
      "  \"value_proposition\": \"Kaspr provides sales, recruitment, and founding professionals with instant access to accurate, compliant, and verified European B2B contact data via an easy-to-use LinkedIn Chrome Extension and integrated platform, enabling faster lead generation, seamless workflow integration, and pipeline growth.\",\n",
      "  \"features\": [\n",
      "    \"Accurate contact data access for over 200 million profiles including 500M+ verified phone numbers and emails\",\n",
      "    \"LinkedIn Chrome Extension to extract contact information directly from prospect profiles\",\n",
      "    \"Bulk data enrichment for lead lists with real-time verified data from 150+ sources\",\n",
      "    \"Native integrations with leading CRMs (HubSpot, Salesforce, Pipedrive, Zoho CRM) and sales tools (Lemlist, Ringover, Aircall, Brevo, Zapier)\",\n",
      "    \"All-in-one prospect management dashboard with automation capabilities\",\n",
      "    \"GDPR and CCPA compliant data sourcing and handling\",\n",
      "    \"No onboarding required with quick start and available training/support resources\"\n",
      "  ],\n",
      "  \"pricing\": \"Available on the Kaspr website pricing page; details not directly provided in the analyzed content\",\n",
      "  \"target_audience\": \"Sales representatives, recruitment professionals, founders, and business teams focused on B2B lead generation and outreach primarily in Europe\",\n",
      "  \"differentiators\": [\n",
      "    \"Focus on European market with unmatched data quality and compliance\",\n",
      "    \"Seamless LinkedIn-integrated workflow allowing contact data retrieval without leaving filtered LinkedIn searches\",\n",
      "    \"Extensive integrations with popular CRM and sales outreach tools for streamlined prospecting and sales processes\"\n",
      "  ],\n",
      "  \"domain\": \"kaspr.io\",\n",
      "  \"is_my_domain\": false\n",
      "}\n",
      "\n",
      "==================================================\n",
      "[COMPETITOR] dealfront.com\n",
      "==================================================\n",
      "{\n",
      "  \"company\": \"Dealfront\",\n",
      "  \"value_proposition\": \"Dealfront offers a comprehensive B2B revenue engine platform that enables sales and marketing teams to create high-quality pipelines and accelerate revenue growth through accurate data, AI insights, and deep account intelligence.\",\n",
      "  \"features\": [\n",
      "    \"Dealfront AI for creating qualified pipelines faster\",\n",
      "    \"ICP Insights for spotting and segmenting best-fit website visitors instantly\",\n",
      "    \"Browser Extension to access compliant deep data on the go\",\n",
      "    \"Buyer Intent Signals to focus on prospects showing real buying intent\",\n",
      "    \"Leadfeeder for identifying companies visiting your website\",\n",
      "    \"Datacare to check, cleanse, enrich, and optimize company data\",\n",
      "    \"Promote module for targeted B2B display advertising\",\n",
      "    \"Target module providing compliant B2B data\",\n",
      "    \"Connect module for deep insights into target accounts\"\n",
      "  ],\n",
      "  \"pricing\": \"Not available. The website provides no explicit pricing details; users are encouraged to book a call to choose the right solution.\",\n",
      "  \"target_audience\": \"Sales and marketing teams in B2B companies, especially those looking to boost lead quality, conversion rates, and pipeline acceleration with compliant, high-quality European B2B data and AI-driven insights.\",\n",
      "  \"differentiators\": [\n",
      "    \"Focus on compliant and highly accurate B2B data for Europe\",\n",
      "    \"Integrated AI tools to generate qualified leads and automate intent scoring\",\n",
      "    \"Multiple modules catering to different stages of revenue generation (data cleansing, visitor identification, targeted ads, data enrichment)\",\n",
      "    \"Strong integrations with CRM and advertising platforms such as Salesforce, HubSpot, Pipedrive, and Google Ads\",\n",
      "    \"Comprehensive playbooks and support to power AI tools and automate workflows\"\n",
      "  ],\n",
      "  \"domain\": \"dealfront.com\",\n",
      "  \"is_my_domain\": false\n",
      "}\n",
      "\n",
      "==================================================\n",
      "[YOUR COMPANY] lusha.com\n",
      "==================================================\n",
      "{\n",
      "  \"company\": \"Lusha\",\n",
      "  \"value_proposition\": \"Lusha offers an AI-powered sales intelligence platform providing accurate B2B data enriched with real-time buying signals and AI workflows to accelerate pipeline growth and streamline revenue teams' efforts.\",\n",
      "  \"features\": [\n",
      "    \"B2B Contact & Company Search to find ideal prospects quickly\",\n",
      "    \"Chrome Extension for capturing leads on LinkedIn and other web sources\",\n",
      "    \"Buyer Intent data and real-time Signals & Alerts for in-market buyer identification\",\n",
      "    \"AI-driven Lead Streaming with daily matched leads and auto-updating prospect playlists\",\n",
      "    \"Automation tools for personalized email engagement and sales meeting analysis\",\n",
      "    \"Data integration with APIs, CRM enrichment, and multi-channel platform sync\",\n",
      "    \"Solutions tailored for sales teams, revenue operations, marketers, and recruiters\"\n",
      "  ],\n",
      "  \"pricing\": \"Flexible pricing plans suitable for companies of all sizes; detailed pricing available on their pricing page with a free start option and custom enterprise plans. Contact sales for detailed quotes.\",\n",
      "  \"target_audience\": \"Revenue teams including sales professionals, revenue operations, marketers, recruiters, and businesses ranging from SMBs to enterprises looking to scale sales and optimize demand generation.\",\n",
      "  \"differentiators\": [\n",
      "    \"Real-time buyer intent signals integrated with AI-powered workflows\",\n",
      "    \"Comprehensive automation and enrichment capabilities to keep CRM data fresh and actionable\",\n",
      "    \"Multi-channel prospecting tools including a Chrome extension and API integrations\",\n",
      "    \"Scalable solutions serving SMBs to enterprise-level organizations\",\n",
      "    \"Highly rated for ease of use and effectiveness in accelerating pipeline growth\"\n",
      "  ],\n",
      "  \"domain\": \"lusha.com\",\n",
      "  \"is_my_domain\": true\n",
      "}\n",
      "\n",
      "==================================================\n",
      "[COMPETITOR] cognism.com\n",
      "==================================================\n",
      "{\n",
      "  \"company\": \"Cognism\",\n",
      "  \"value_proposition\": \"Cognism is a premium sales intelligence platform that empowers GTM teams to break performance records, acquire highly targeted leads on-demand, and grow revenue by delivering high-quality, compliant data and actionable buyer insights.\",\n",
      "  \"features\": [\n",
      "    \"Sales Companion: a revenue growth center for GTM teams that integrates data and insights into workflows\",\n",
      "    \"Buyer signals: actionable insights to find and engage the next best customer\",\n",
      "    \"Data-as-a-Service: direct delivery of insights and data into customer data warehouses\",\n",
      "    \"Integrations: seamless syncing of high-quality data to existing tech stacks\",\n",
      "    \"Diamond Data\\u00ae: Cognism's proprietary data technology ensuring data quality and compliance\",\n",
      "    \"Compliance: GDPR and other data privacy regulation compliant data practices\",\n",
      "    \"Use case support for Sales, Marketing, and Revenue Operations teams\"\n",
      "  ],\n",
      "  \"pricing\": \"Pricing details are available upon request or consultation; publicly available specific pricing information is not provided on the website.\",\n",
      "  \"target_audience\": \"Sales, Marketing, and Revenue Operations professionals at B2B organizations seeking to accelerate pipeline generation, improve targeting, and grow revenue through premium sales intelligence and data-driven insights.\",\n",
      "  \"differentiators\": [\n",
      "    \"Proprietary Diamond Data\\u00ae technology guarantees high-quality, GDPR-compliant data\",\n",
      "    \"Comprehensive platform combining sales intelligence, buyer signals, data delivery, and integrations in one solution\",\n",
      "    \"Strong focus on compliance with global data privacy regulations\",\n",
      "    \"Used by over 4,000 companies worldwide, demonstrating established market trust\",\n",
      "    \"Tailored solutions for multiple go-to-market roles including Sales, Marketing, and RevOps\"\n",
      "  ],\n",
      "  \"domain\": \"cognism.com\",\n",
      "  \"is_my_domain\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Display: Show each company profile\n",
    "\n",
    "for profile in company_profiles:\n",
    "    label = \"YOUR COMPANY\" if profile.get('is_my_domain') else \"COMPETITOR\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"[{label}] {profile.get('domain', 'Unknown')}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(json.dumps(profile, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSUyebTExopp",
    "outputId": "6dfdc02a-366e-4832-8630-da91b1ee1e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPETITIVE COMPARISON\n",
      "============================================================\n",
      "\n",
      "### 1. Comparison Table\n",
      "\n",
      "| Company    | Key Features                                                                                                     | Pricing                                     | Target Market                                   | Unique Differentiators                                      |\n",
      "|------------|-----------------------------------------------------------------------------------------------------------------|---------------------------------------------|------------------------------------------------|-------------------------------------------------------------|\n",
      "| **Lusha**  | - B2B Contact & Company Search<br>- Chrome Extension<br>- Buyer Intent Data & Signals<br>- AI Lead Streaming<br>- Automation for email & meeting analysis<br>- API & CRM integrations<br>- Multi-channel prospecting | Flexible plans, free option, custom enterprise pricing; details on website                          | Revenue teams (Sales, RevOps, Marketing, Recruiting) from SMB to Enterprise                          | - Real-time AI-driven intent signals<br>- Strong automation & enrichment<br>- Scalable enterprise & SMB use<br>- Multi-channel workflows |\n",
      "| **Kaspr**  | - 200M+ profiles, 500M+ verified contacts<br>- LinkedIn Chrome extension<br>- Bulk list enrichment<br>- Integrations (HubSpot, Salesforce, etc.)<br>- Prospect management dashboard<br>- GDPR & CCPA compliant | Pricing on website (not disclosed here)               | Sales, recruitment, founders, and B2B teams focused on Europe                | - Strong European market focus<br>- LinkedIn-integrated workflow for in-session contact retrieval<br>- CRM & sales tool ecosystem integration  |\n",
      "| **Dealfront** | - AI-driven pipeline creation<br>- ICP insights & Buyer Intent signals<br>- Browser extension<br>- Data cleansing & enrichment<br>- Targeted B2B ads<br>- Multiple modules (Datacare, Promote, Target, Connect)<br>- Integrations (Salesforce, HubSpot, Google Ads) | No public pricing; requires sales consultation             | Sales & marketing teams in B2B, especially Europe, seeking AI-powered insights & ads | - AI-powered intent scoring & segmentation<br>- Comprehensive revenue enablement modules including ads<br>- Strong CRM & ad platform integrations |\n",
      "| **Cognism**  | - Sales Companion workflow integration<br>- Buyer signals & insights<br>- Data-as-a-Service to warehouses<br>- Proprietary Diamond DataÂ® tech<br>- GDPR-compliant<br>- Broad GTM use cases<br>- Integrations | Pricing by consultation                    | Sales, Marketing, Revenue Ops in B2B worldwide                   | - Proprietary data tech ensuring top compliance & quality<br>- Large global customer base<br>- Comprehensive all-in-one intelligence & integration platform  |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Competitorsâ€™ Strengths vs Lusha\n",
      "\n",
      "- **Kaspr**  \n",
      "  - Strong LinkedIn workflow integration allowing instant data extraction during LinkedIn prospecting (more seamless in-platform data retrieval vs Lusha's Chrome Extension which requires user interaction).  \n",
      "  - Focus on exhaustive verified contact data in Europe with strong compliance emphasis.  \n",
      "  - Bulk enrichment capabilities for lists enabling efficient lead list management.\n",
      "\n",
      "- **Dealfront**  \n",
      "  - Advanced AI tools for pipeline generation and ICP segmentation beyond contact data.  \n",
      "  - Diverse modular platform covering ads, visitor tracking, data cleansing in one suiteâ€”broader revenue enablement coverage.  \n",
      "  - Buyer intent signals combined with targeted B2B advertising capabilities, enabling more proactive multi-channel campaigns.\n",
      "\n",
      "- **Cognism**  \n",
      "  - Proprietary Diamond DataÂ® technology ensures very high quality and compliant data, especially robust for GDPR.  \n",
      "  - Data-as-a-Service delivery into customer warehousesâ€”better for enterprises needing embedded data for analytics across systems.  \n",
      "  - Large global reach and established enterprise footprint, trusted by thousands of companies worldwide.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Lushaâ€™s Competitive Advantages\n",
      "\n",
      "- **Real-time AI-driven buyer intent and lead streaming** keeps prospect playlists fresh and actionable, enabling revenue teams to prioritize hottest leads.  \n",
      "- **Comprehensive automation** tools (including email personalization and sales meeting analysis) help accelerate outreach and pipeline velocity beyond raw data access.  \n",
      "- **Multi-channel prospecting suite** with Chrome extension and API-based integrations suits a wide variety of workflows, from manual social selling to automated CRM enrichment.  \n",
      "- Flexible and transparent pricing options with a free tier and custom scaling make it accessible to SMBs and large enterprises alike.  \n",
      "- Strong reputation for ease-of-use and effectiveness in pipeline acceleration, widely rated by users.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Areas Where Lusha Could Improve\n",
      "\n",
      "- **Data Volume & European Market Depth:** Kaspr and Dealfront emphasize strong verified European contact databases and compliance. Lusha could enhance verification and data quantity depth specifically in European markets to compete more aggressively.  \n",
      "- **Modular Revenue Suite:** Dealfrontâ€™s multi-module approach (ads, ICP insights, data cleansing) provides end-to-end revenue enablement vs Lushaâ€™s primarily lead and intent focus. Lusha could expand additional modules to cover broader campaign execution or data hygiene features.  \n",
      "- **Bulk Data Enrichment at Scale:** Kaspr offers extensive bulk enrichment and list management. Lusha can improve bulk data processing capabilities and more advanced prospect list workflows inside the platform.  \n",
      "- **Deeper Embedded Analytics & Data Delivery:** Cognismâ€™s Data-as-a-Service and warehouse integration is attractive for enterprises needing tight control over data pipelines. Lusha could develop enhanced enterprise-grade APIs and direct data delivery options for embedding intelligence into broader BI systems.  \n",
      "- **Pricing Transparency and Customization:** While flexible, Lusha's pricing details require user inquiry beyond free tier. Providing more transparent mid-market pricing tiers online could improve user confidence and conversion.\n",
      "\n",
      "---\n",
      "\n",
      "**Summary:** Lusha leads with AI-driven intent signals, automation, and multi-channel prospecting ease, serving a broad audience from SMB to enterprise. However, competitors Kaspr and Dealfront outshine Lusha in Europe-focused verified data and broader revenue enablement modules, while Cognism excels in data quality and enterprise-grade integrations. Lusha should deepen European data depth, diversify modular features (ads, cleansing), and enhance bulk enrichment and embedded data delivery to close these gaps.\n"
     ]
    }
   ],
   "source": [
    "# Execute: Generate competitive comparison of all companies\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPETITIVE COMPARISON\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "profiles_summary = json.dumps(company_profiles, indent=2)\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"Compare these companies against {MY_BRAND}. Create a competitive analysis:\n",
    "1. Comparison table (features, pricing, target market)\n",
    "2. Each competitor's strengths vs {MY_BRAND}\n",
    "3. {MY_BRAND}'s competitive advantages\n",
    "4. Areas where {MY_BRAND} could improve\n",
    "\n",
    "Be direct and actionable.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Company profiles:\\n{profiles_summary}\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1500\n",
    ")\n",
    "\n",
    "comparison_analysis = response.choices[0].message.content\n",
    "print(comparison_analysis)\n",
    "\n",
    "# Store for executive summary\n",
    "deep_insights = {\n",
    "    'company_profiles': company_profiles,\n",
    "    'comparison': comparison_analysis\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0RrDIXDdIO3"
   },
   "source": [
    "---\n",
    "## Section 5: Executive Summary\n",
    "\n",
    "This section compiles all findings into a comprehensive competitive intelligence report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQmU2hHFdIO3",
    "outputId": "d050cb7a-f0c0-4767-944f-3a71f7d8975d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executive summary data compiled.\n",
      "\n",
      "Sections included:\n",
      "  - SERP Rankings: 3 keywords\n",
      "  - AI Perception: 9/12 mentions\n",
      "  - Competitor Insights: 4 pages\n",
      "  - Company Profiles: 4 companies\n"
     ]
    }
   ],
   "source": [
    "# Execute: Compile all data into a summary structure\n",
    "\n",
    "executive_summary = {\n",
    "    'brand': MY_BRAND,\n",
    "    'domain': MY_DOMAIN,\n",
    "    'market': COUNTRY,\n",
    "    'generated_at': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "\n",
    "    # SERP Rankings\n",
    "    'serp': {\n",
    "        'keywords_tracked': len(rankings['keywords']),\n",
    "        'rankings': {kw: data['my_position'] for kw, data in rankings['keywords'].items()},\n",
    "        'main_competitors': [c['domain'] for c in rankings['main_competitors'][:3]]\n",
    "    },\n",
    "\n",
    "    # AI Perception\n",
    "    'ai_perception': {\n",
    "        'engines_queried': [r['engine_name'] for r in ai_results],\n",
    "        'mentions': sum(1 for r in ai_results if r.get('mentioned')),\n",
    "        'total_queries': len(ai_results)\n",
    "    },\n",
    "\n",
    "    # Competitor Insights\n",
    "    'competitor_insights': competitor_insights,\n",
    "\n",
    "    # Deep Analysis (now contains company_profiles and comparison)\n",
    "    'deep_insights': deep_insights\n",
    "}\n",
    "\n",
    "print(\"Executive summary data compiled.\")\n",
    "print(f\"\\nSections included:\")\n",
    "print(f\"  - SERP Rankings: {executive_summary['serp']['keywords_tracked']} keywords\")\n",
    "print(f\"  - AI Perception: {executive_summary['ai_perception']['mentions']}/{executive_summary['ai_perception']['total_queries']} mentions\")\n",
    "print(f\"  - Competitor Insights: {len(competitor_insights)} pages\")\n",
    "print(f\"  - Company Profiles: {len(deep_insights.get('company_profiles', []))} companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GY2aagZEdIO3",
    "outputId": "ded8e5ae-3399-4e41-e0d8-5ad52fa8f65c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating executive report with GPT...\n",
      "\n",
      "============================================================\n",
      "EXECUTIVE REPORT: Lusha\n",
      "Generated: 2026-01-14 14:59:05\n",
      "============================================================\n",
      "\n",
      "Executive Competitive Intelligence Report: Lusha\n",
      "\n",
      "1. Overall Competitive Position\n",
      "Lusha holds a credible position as an AI-powered sales intelligence platform but currently lacks prominent visibility in key SERP rankings such as \"lead generation software\" and \"B2B contact database,\" limiting its market discoverability relative to competitors.\n",
      "\n",
      "2. Key Strengths\n",
      "- Offers AI-enhanced B2B data enriched with real-time buying signals and AI workflows, supporting accelerated pipeline growth.\n",
      "- Flexible pricing models including free starter options and customizable enterprise plans cater to a broad customer base.\n",
      "- Mentioned in the majority of AI-related search queries, enhancing technological thought leadership perception.\n",
      "\n",
      "3. Areas for Improvement\n",
      "- Suboptimal search engine ranking in critical keywords diminishes organic lead generation and brand exposure.\n",
      "- Pricing transparency is moderate; enterprise plans require sales engagement which may deter self-service buyers.\n",
      "- Competitive differentiation versus rivals like Kaspr and Dealfront is not distinctly pronounced in marketing messaging.\n",
      "\n",
      "4. Top 3 Recommended Actions\n",
      "- Invest in targeted SEO campaigns focused on high-value keywords (\"lead generation software,\" \"B2B contact database,\" \"sales prospecting tool\") to improve top-10 SERP rankings.\n",
      "- Enhance website content clarity on pricing structures and value propositions to streamline buyer decision-making and reduce friction.\n",
      "- Amplify unique AI workflow capabilities and real-time signal benefits through case studies and comparative marketing to differentiate from competitors effectively.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Execute: GPT generates comprehensive executive report\n",
    "\n",
    "if openai_client:\n",
    "    print(\"Generating executive report with GPT...\\n\")\n",
    "\n",
    "    # Build context from all sections\n",
    "    full_context = f\"\"\"\n",
    "COMPETITIVE INTELLIGENCE REPORT\n",
    "Brand: {MY_BRAND}\n",
    "Domain: {MY_DOMAIN}\n",
    "Market: {COUNTRY}\n",
    "\n",
    "=== SERP RANKINGS ===\n",
    "\"\"\"\n",
    "    for kw, data in rankings['keywords'].items():\n",
    "        pos = data['my_position'] or \"Not in top 10\"\n",
    "        full_context += f\"\\n'{kw}': Position {pos}\"\n",
    "\n",
    "    full_context += f\"\\n\\nMain Competitors: {', '.join(executive_summary['serp']['main_competitors'])}\"\n",
    "\n",
    "    full_context += \"\\n\\n=== AI PERCEPTION ===\"\n",
    "    full_context += f\"\\nMentioned in {executive_summary['ai_perception']['mentions']}/{executive_summary['ai_perception']['total_queries']} AI engine queries\"\n",
    "\n",
    "    full_context += \"\\n\\n=== COMPANY PROFILES ===\"\n",
    "    for profile in deep_insights.get('company_profiles', []):\n",
    "        label = \"(YOUR COMPANY)\" if profile.get('is_my_domain') else \"\"\n",
    "        full_context += f\"\\n{profile.get('domain', 'Unknown')} {label}\"\n",
    "        full_context += f\"\\n  Value prop: {profile.get('value_proposition', 'N/A')}\"\n",
    "        full_context += f\"\\n  Pricing: {profile.get('pricing', 'N/A')}\"\n",
    "\n",
    "    full_context += \"\\n\\n=== COMPETITIVE COMPARISON ===\"\n",
    "    full_context += f\"\\n{deep_insights.get('comparison', 'N/A')[:500]}...\"\n",
    "\n",
    "    # Generate executive report\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a senior competitive intelligence analyst. Generate a concise executive report with:\n",
    "1. Overall competitive position (1-2 sentences)\n",
    "2. Key strengths (2-3 bullets)\n",
    "3. Areas for improvement (2-3 bullets)\n",
    "4. Top 3 recommended actions\n",
    "\n",
    "Be direct and actionable.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Generate an executive report based on this data:\\n{full_context}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=2000\n",
    "    )\n",
    "\n",
    "    executive_report = response.choices[0].message.content\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(f\"EXECUTIVE REPORT: {MY_BRAND}\")\n",
    "    print(f\"Generated: {executive_summary['generated_at']}\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    print(executive_report)\n",
    "    print()\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"Skipping executive report (no OpenAI API key configured)\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}